{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add PyDatAnalysis to path\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, \"/Users/owensheekey/Documents/Research/PyDatAnalysis\")\n",
    "\n",
    "export_path = 'Exports/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from progressbar import progressbar\n",
    "from src.DatObject.Make_Dat import get_dat, get_dats\n",
    "import src.UsefulFunctions as U\n",
    "from src.DataStandardize.ExpSpecific.Feb21 import Feb21Exp2HDF, Feb21ExpConfig\n",
    "from src.DataStandardize.ExpConfig import ExpConfigGroupDatAttribute, ExpConfigBase\n",
    "import multiprocessing as mp\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "import lmfit as lm\n",
    "from typing import TYPE_CHECKING, Iterable, Optional\n",
    "from src.DatObject.Attributes.Transition import i_sense_digamma, i_sense, i_sense_digamma_quad\n",
    "from src.UsefulFunctions import edit_params\n",
    "from src.DatObject.Attributes.SquareEntropy import square_wave_time_array, integrate_entropy\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "import src.UsefulFunctions as U\n",
    "import scipy.io\n",
    "from scipy.interpolate import RectBivariateSpline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def narrow_fit(dat, width, **kwargs):\n",
    "    '''\n",
    "    Get a fit only including +/- width in dat.x around center of transition\n",
    "    kwargs is the stuff to pass to get_fit\n",
    "    Return a fit\n",
    "    '''\n",
    "    out = dat.SquareEntropy.get_Outputs(existing_only=True)\n",
    "    x = np.copy(out.x)\n",
    "    y = np.copy(out.averaged)\n",
    "    y = np.mean(y[(0, 2), :], axis=0)\n",
    "\n",
    "    start_ind = np.nanargmin(np.abs(np.add(x, width)))\n",
    "    end_ind = np.nanargmin(np.abs(np.subtract(x, width)))\n",
    "\n",
    "    x[:start_ind] = [np.nan] * start_ind\n",
    "    x[end_ind:] = [np.nan] * (len(x) - end_ind)\n",
    "\n",
    "    y[:start_ind] = [np.nan] * start_ind\n",
    "    y[end_ind:] = [np.nan] * (len(y) - end_ind)\n",
    "\n",
    "    fit = dat.SquareEntropy.get_fit(\n",
    "        x=x,\n",
    "        data=y,\n",
    "        **kwargs)\n",
    "    return fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def narrow_fit_trans_only(dat, width, **kwargs):\n",
    "    '''\n",
    "    Get a fit only including +/- width in dat.x around center of transition\n",
    "    kwargs is the stuff to pass to get_fit\n",
    "    Return a fit\n",
    "    '''\n",
    "    x = np.copy(dat.Transition.avg_x)\n",
    "    y = np.copy(dat.Transition.avg_data)\n",
    "\n",
    "    start_ind = np.nanargmin(np.abs(np.add(x, width)))\n",
    "    end_ind = np.nanargmin(np.abs(np.subtract(x, width)))\n",
    "\n",
    "    x[:start_ind] = [np.nan] * start_ind\n",
    "    x[end_ind:] = [np.nan] * (len(x) - end_ind)\n",
    "\n",
    "    y[:start_ind] = [np.nan] * start_ind\n",
    "    y[end_ind:] = [np.nan] * (len(y) - end_ind)\n",
    "\n",
    "    fit = dat.SquareEntropy.get_fit(\n",
    "        x=x,\n",
    "        data=y,\n",
    "        **kwargs)\n",
    "    return fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def do_calc(datnum, overwrite=True):\n",
    "    \"\"\"Just a function which can be passed to a process pool for faster calculation\"\"\"\n",
    "    save_name = 'SPS.01'\n",
    "\n",
    "    dat = get_dat(datnum)\n",
    "\n",
    "    setpoints = [0.01, None]\n",
    "\n",
    "    # Get other inputs\n",
    "    setpoint_times = square_wave_time_array(dat.SquareEntropy.square_awg)\n",
    "    sp_start, sp_fin = [U.get_data_index(setpoint_times, sp) for sp in setpoints]\n",
    "    logger.debug(f'Setpoint times: {setpoints}, Setpoint indexs: {sp_start, sp_fin}')\n",
    "\n",
    "    # Run Fits\n",
    "    pp = dat.SquareEntropy.get_ProcessParams(name=None,  # Load default and modify from there\n",
    "                                             setpoint_start=sp_start, setpoint_fin=sp_fin,\n",
    "                                             transition_fit_func=i_sense,\n",
    "                                             save_name=save_name)\n",
    "    out = dat.SquareEntropy.get_Outputs(name=save_name, inputs=None, process_params=pp, overwrite=overwrite)\n",
    "    dat.Entropy.get_fit(which='avg', name=save_name, data=out.average_entropy_signal, x=out.x, check_exists=False,\n",
    "                        overwrite=overwrite)\n",
    "    [dat.Entropy.get_fit(which='row', row=i, name=save_name,\n",
    "                         data=row, x=out.x, check_exists=False,\n",
    "                         overwrite=overwrite) for i, row in enumerate(out.entropy_signal)]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_deltaT(dat):\n",
    "    \"\"\"Returns deltaT of a given dat in mV\"\"\"\n",
    "    ho1 = dat.AWG.max(0)  # 'HO1/10M' gives nA * 10\n",
    "    t = dat.Logs.temps.mc\n",
    "\n",
    "    # Datnums to search through (only thing that should be changed)\n",
    "    datnums = set(range(1312, 1451+1)) - set(range(1312, 1451+1, 4))\n",
    "    # datnums = set()\n",
    "    # for j in range(5):\n",
    "    #     datnums = datnums.union(set(range(28 * j + 1312, 28 * j + 1312 + 4 * 7 + 1)) - set([28 * j + 1312 + 4 * i for i in range(8)]))\n",
    "    # datnums = list(datnums)\n",
    "\n",
    "    dats = get_dats(datnums)\n",
    "\n",
    "    dats = [d for d in dats if np.isclose(d.Logs.temps.mc, dat.Logs.temps.mc, rtol=0.1)]  # Get all dats where MC temp is within 10%\n",
    "    bias_lookup = np.array([d.Logs.fds['HO1/10M'] for d in dats])\n",
    "\n",
    "    indp = np.argmin(abs(bias_lookup - ho1))\n",
    "    indm = np.argmin(abs(bias_lookup + ho1))\n",
    "    theta_z = np.nanmean([d.Transition.avg_fit.best_values.theta for d in dats if d.Logs.fds['HO1/10M'] == 0])\n",
    "\n",
    "    # temp_lookup = np.array([d.Logs.temps.mc for d in dats])\n",
    "    # bias_lookup = np.array([d.Logs.fds['HO1/10M'] for d in dats])\n",
    "    #\n",
    "    # indp = np.argmin(temp_lookup - t + bias_lookup - ho1)\n",
    "    # indm = np.argmin(temp_lookup - t + bias_lookup + ho1)\n",
    "    # indz = np.argmin(temp_lookup - t + bias_lookup)\n",
    "\n",
    "    theta_p = dats[indp].Transition.avg_fit.best_values.theta\n",
    "    theta_m = dats[indm].Transition.avg_fit.best_values.theta\n",
    "    # theta_z = dats[indz].Transition.avg_fit.best_values.theta\n",
    "    return (theta_p + theta_m) / 2 - theta_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "NRG = scipy.io.loadmat('Results.mat')\n",
    "occ = NRG[\"Occupation_mat\"]\n",
    "ens = np.reshape(NRG[\"Ens\"], 401)\n",
    "ts  = np.reshape(NRG[\"Ts\"], 70)\n",
    "ens = np.flip(ens)\n",
    "occ = np.flip(occ, 0)\n",
    "interp = RectBivariateSpline(ens, np.log10(ts), occ, kx=1,ky=1)\n",
    "def interpNRG(x, dx, ampconst, amplin, center, lin, const, logt):\n",
    "    ens = np.multiply(np.add(x, center),dx)\n",
    "    occ = [1 - interp(en, logt)[0][0] for en in ens]\n",
    "    lin_amp = np.multiply(ens, amplin)\n",
    "    amp = np.add(lin_amp, ampconst)\n",
    "    result = occ * amp + const + lin*x\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datnums = set(range(1869, 1919)) - set(range(1870, 1919, 2))\n",
    "# transdatnums = set(range(1869, 1919)) - set(range(1869, 1919, 2))\n",
    "datnums = np.sort(list(set(range(2089, 2095)) - set(range(2090, 2095, 2))))\n",
    "transdatnums = np.sort(list(set(range(2089, 2095)) - set(range(2089, 2095, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "dats = get_dats(list(datnums), overwrite=False)\n",
    "transdats = get_dats(list(transdatnums), overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "escs = [dat.Logs.fds[\"ESC\"] for dat in dats]\n",
    "datnums = [dat.datnum for dat in dats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (3 of 3) |##########################| Elapsed Time: 0:07:44 Time:  0:07:44\n"
     ]
    }
   ],
   "source": [
    "out = [do_calc(dn) for dn in progressbar(datnums)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Θ = 3.9\n",
    "fit = transdats[0].Transition.get_fit(which='avg', check_exists=False)\n",
    "params = fit.params\n",
    "params.add('g', value=0, vary=True, min=-50, max=1000)\n",
    "new_pars = edit_params(params, param_name='theta', value=Θ, vary=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (3 of 3) |##########################| Elapsed Time: 0:01:30 Time:  0:01:30\n"
     ]
    }
   ],
   "source": [
    "amp_digamma_ = [narrow_fit_trans_only(\n",
    "    dat,\n",
    "    600,\n",
    "    which='avg', \n",
    "    initial_params=new_pars, \n",
    "    fit_func=i_sense_digamma, \n",
    "    check_exists=False).best_values.amp\n",
    "for dat in progressbar(transdats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8915637252820501, 0.6737286118654073, 0.48944639212080143]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amp_digamma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (3 of 3) |##########################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "g_digamma_ = [narrow_fit_trans_only(\n",
    "    dat,\n",
    "    600,\n",
    "    initial_params=new_pars, \n",
    "    fit_func=i_sense_digamma, \n",
    "    check_exists=False).best_values.g\n",
    "for dat in progressbar(transdats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (3 of 3) |##########################| Elapsed Time: 0:00:01 Time:  0:00:01\n"
     ]
    }
   ],
   "source": [
    "amp_digamma_cold = [narrow_fit(\n",
    "    dat,\n",
    "    600,\n",
    "    which='avg', \n",
    "    initial_params=new_pars, \n",
    "    fit_func=i_sense_digamma, \n",
    "    check_exists=False).best_values.amp\n",
    "for dat in progressbar(dats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (3 of 3) |##########################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "g_digamma_cold = [narrow_fit(\n",
    "    dat,\n",
    "    600,\n",
    "    initial_params=new_pars, \n",
    "    fit_func=i_sense_digamma, \n",
    "    check_exists=False).best_values.g\n",
    "for dat in progressbar(dats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (3 of 3) |##########################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "mids_digamma_ = [narrow_fit(\n",
    "    dat,\n",
    "    600,\n",
    "    initial_params=new_pars, \n",
    "    fit_func=i_sense_digamma, \n",
    "    check_exists=False).best_values.mid\n",
    "for dat in progressbar(dats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrg_pars = lm.Parameters()\n",
    "nrg_pars.add_many(\n",
    "    ('dx', -0.0007, True, None, None, None, None),\n",
    "    ('ampconst', 2, True, 0.1, None, None, None),\n",
    "    ('amplin', 0.01, True, None, None, None, None),\n",
    "    ('center', 0, True, None, None, None, None),\n",
    "    ('lin', 0.1, True, 0.001, None, None, None),\n",
    "    ('const', 0, True, None, None, None, None),\n",
    "    ('logt', -2, False, None, None, None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit0 = narrow_fit_trans_only(\n",
    "    transdats[0],\n",
    "    1000,\n",
    "    initial_params=nrg_pars, \n",
    "    fit_func=interpNRG, \n",
    "    check_exists=False, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Model]]\n",
      "    Model(interpNRG)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 57\n",
      "    # data points      = 1505\n",
      "    # variables        = 6\n",
      "    chi-square         = 0.00101987\n",
      "    reduced chi-square = 6.8037e-07\n",
      "    Akaike info crit   = -21365.9606\n",
      "    Bayesian info crit = -21334.0613\n",
      "[[Variables]]\n",
      "    dx:       -0.00271179 +/- 1.8832e-06 (0.07%) (init = -0.0007)\n",
      "    ampconst:  0.90199648 +/- 9.7128e-05 (0.01%) (init = 2)\n",
      "    amplin:    0.00309079 +/- 1.9652e-04 (6.36%) (init = 0.01)\n",
      "    center:   -2.16684036 +/- 0.00333531 (0.15%) (init = 0)\n",
      "    lin:       0.00148281 +/- 3.6295e-07 (0.02%) (init = 0.1)\n",
      "    const:     6.78861248 +/- 6.5543e-05 (0.00%) (init = 0)\n",
      "    logt:     -2 (fixed)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(lin, const)       = -0.885\n",
      "    C(ampconst, const)  = -0.705\n",
      "    C(amplin, lin)      =  0.665\n",
      "    C(ampconst, lin)    =  0.618\n",
      "    C(amplin, const)    = -0.579\n",
      "    C(dx, center)       = -0.434\n",
      "    C(dx, ampconst)     =  0.357\n",
      "    C(center, const)    =  0.345\n",
      "    C(center, lin)      = -0.304\n",
      "    C(amplin, center)   = -0.299\n",
      "    C(dx, const)        = -0.252\n",
      "    C(dx, lin)          =  0.217\n",
      "    C(ampconst, center) = -0.141\n"
     ]
    }
   ],
   "source": [
    "print(fit0.fit_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrg_pars = lm.Parameters()\n",
    "nrg_pars.add_many(\n",
    "    ('dx', -0.0007, True, None, None, None, None),\n",
    "    ('ampconst', 2, True, 0.1, None, None, None),\n",
    "    ('amplin', 0.01, True, -0.01, 0.01, None, None),\n",
    "    ('center', 0, True, None, None, None, None),\n",
    "    ('lin', 0.1, True, 0.001, None, None, None),\n",
    "    ('const', 0, True, None, None, None, None),\n",
    "    ('logt', -4, False, None, None, None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit1 = narrow_fit_trans_only(\n",
    "    transdats[1],\n",
    "    500,\n",
    "    initial_params=nrg_pars, \n",
    "    fit_func=interpNRG, \n",
    "    check_exists=False, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Model]]\n",
      "    Model(interpNRG)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 14000\n",
      "    # data points      = 845\n",
      "    # variables        = 6\n",
      "    chi-square         = 49.9044747\n",
      "    reduced chi-square = 0.05948090\n",
      "    Akaike info crit   = -2378.69593\n",
      "    Bayesian info crit = -2350.25991\n",
      "##  Warning: uncertainties could not be estimated:\n",
      "[[Variables]]\n",
      "    dx:        0.00799352 (init = -0.0007)\n",
      "    ampconst:  0.10498756 (init = 2)\n",
      "    amplin:   -9.9989e-05 (init = 0.01)\n",
      "    center:    317.268088 (init = 0)\n",
      "    lin:       0.00100050 (init = 0.1)\n",
      "    const:     7.52098729 (init = 0)\n",
      "    logt:     -4 (fixed)\n"
     ]
    }
   ],
   "source": [
    "print(fit1.fit_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrg_pars = lm.Parameters()\n",
    "nrg_pars.add_many(\n",
    "    ('dx', -0.0007, True, None, 0, None, None),\n",
    "    ('ampconst', 2, True, 0.1, None, None, None),\n",
    "    ('amplin', 0.01, True, None, None, None, None),\n",
    "    ('center', 0, True, None, None, None, None),\n",
    "    ('lin', 0.1, True, 0.001, None, None, None),\n",
    "    ('const', 0, True, None, None, None, None),\n",
    "    ('logt', -5, False, None, None, None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit2 = narrow_fit_trans_only(\n",
    "    transdats[2],\n",
    "    700,\n",
    "    initial_params=nrg_pars, \n",
    "    fit_func=interpNRG, \n",
    "    check_exists=False, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dx=-8.8218e-05\n",
       "ampconst=294.62\n",
       "amplin=0.001\n",
       "center=7781.9\n",
       "lin=0.001\n",
       "const=6.1519\n",
       "logt=-5"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit2.best_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrgfits = [fit0, fit1, fit2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(mode='markers', x=escs, y=amp_digamma_cold, text=datnums, name=\"Entropy fits\"))\n",
    "fig.add_trace(go.Scatter(mode='markers', x=escs, y=amp_digamma_, text=transdatnums, name=\"Transition fits\"))\n",
    "\n",
    "fig.update_layout(xaxis_title='ESC/ mV', yaxis_title='Amplitude /nA',\n",
    "                      title=f'Dats {dats[0].datnum} - {dats[-1].datnum}')\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig.write_html(f'Exports/Ampls_03_12_dats{datnums[0]}_{datnums[-1]}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(mode='markers', x=escs, y=np.array(g_digamma_cold)/Θ, text=datnums, name=\"Entropy fits\"))\n",
    "fig.add_trace(go.Scatter(mode='markers', x=escs, y=np.array(g_digamma_)/Θ, text=transdatnums, name=\"Transition fits\"))\n",
    "fig.update_layout(xaxis_title='ESC/ mV', yaxis_title='Gamma/Theta /arb',\n",
    "                      title=f'Dats {dats[0].datnum} - {dats[-1].datnum}')\n",
    "\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig.write_html(f'Exports/Gammas_03_12_dats{datnums[0]}_{datnums[-1]}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |#                                                  | 2 Elapsed Time: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "for i, dat in progressbar(enumerate(transdats)):\n",
    "    x = np.copy(dat.Transition.avg_x)\n",
    "    y = np.copy(dat.Transition.avg_data)\n",
    "    \n",
    "    xfit = np.linspace(-2000,2000,1001)\n",
    "\n",
    "    yfit = nrgfits[i].eval_fit(xfit) - nrgfits[i].best_values.lin*xfit\n",
    "    fig.add_trace(go.Scatter(mode='markers', x=x, y=y - nrgfits[i].best_values.lin*x, name=f'{transdatnums[i]}d'))\n",
    "    fig.add_trace(go.Scatter(mode='lines', x=xfit, y=yfit, name=f'{transdatnums[i]}f', marker_color='grey'))\n",
    "fig.update_layout(xaxis_title='ACC/100 /mV', yaxis_title='Current /nA',\n",
    "                      title=f'Dat {dats[0].datnum} - {dats[-1].datnum}')\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = get_dat(2089)\n",
    "data = dat.SquareEntropy.get_Outputs(name='SPS.01').average_entropy_signal\n",
    "ii = dat.Entropy.get_integration_info()\n",
    "dx = ii.dx\n",
    "dt = ii.dT\n",
    "x = dat.SquareEntropy.avg_x\n",
    "i = 0\n",
    "ens = np.multiply(np.add(x, nrgfits[i].best_values.center), nrgfits[i].best_values.dx)\n",
    "val = [1 - interp(en, nrgfits[i].best_values.logt)[0][0] for en in ens]\n",
    "\n",
    "amp = nrgfits[i].best_values.ampconst + np.multiply(nrgfits[i].best_values.amplin,val)\n",
    "integrated = np.nancumsum(data, axis=-1) * dx / amp / dt\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(mode='markers', x=x, y=amp))\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(f'Exports/NRG_fits_linear_amp{datnums[0]}_{datnums[-1]}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaT = [get_deltaT(dat) for dat in dats]\n",
    "ampl = amp_digamma_cold\n",
    "for i, dat in enumerate(dats):\n",
    "    dat.Entropy.set_integration_info(dT=deltaT[i], amp=ampl[i], overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "int_ents = []\n",
    "for i in range(len(dats)):\n",
    "    int_ent = integrate_entropy(out[i].average_entropy_signal, dats[i].Entropy.integration_info.sf)\n",
    "    int_ents.append(int_ent[-1])\n",
    "    fig.add_trace(go.Scatter(mode='markers', \n",
    "                             x=np.subtract(out[i].x, mids_digamma_[i]), \n",
    "                             y=int_ent,\n",
    "                             name= f'g/t:{np.divide(g_digamma_,Θ)[i]:.2f}, dat{dats[i].datnum}, ESS:{dats[i].Logs.fds[\"ESS\"]}'))\n",
    "\n",
    "fig.add_trace(go.Scatter(mode='lines', x=[-400,400], y=[np.log(2), np.log(2)], name=\"Log2\"))  \n",
    "fig.add_trace(go.Scatter(mode='lines', x=[-400,400], y=[np.log(3), np.log(3)], name=\"Log3\"))  \n",
    "fig.update_layout(xaxis_title='ACC/100 /mV', yaxis_title='Entropy /kb',\n",
    "                      title=f'Dats {dats[0].datnum} - {dats[-1].datnum}')\n",
    "fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(f'Exports/IntEntropy_03_12_dats{datnums[0]}_{datnums[-1]}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escs1 = []\n",
    "# escs2 = []\n",
    "# int_ents1 = []\n",
    "# int_ents2 = []\n",
    "# datnums1 = []\n",
    "# datnums2 = []\n",
    "# for i in range(len(escs)):\n",
    "#     if dats[i].datnum >= 1941:\n",
    "#         escs2.append(escs[i])\n",
    "#         int_ents2.append(int_ents[i])\n",
    "#         datnums2.append(dats[i].datnum)\n",
    "#     else:\n",
    "#         escs1.append(escs[i])\n",
    "#         int_ents1.append(int_ents[i])\n",
    "#         datnums1.append(dats[i].datnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "ents = [dat.Entropy.get_fit(which='avg', name=\"SPS.005\", check_exists=True).best_values.dS for dat in dats]\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(mode='markers+lines', \n",
    "                         x=escs, y=int_ents, \n",
    "                         text=[dat.datnum for dat in dats], \n",
    "                         name=\"Int\"))\n",
    "fig.add_trace(go.Scatter(mode='markers+lines', \n",
    "                         x=escs, y=ents, \n",
    "                         text=[dat.datnum for dat in dats], \n",
    "                         name=\"Fit\"))\n",
    "# fig.add_trace(go.Scatter(mode='markers+lines', \n",
    "#                          x=escs1, y=int_ents1, \n",
    "#                          text=datnums1, \n",
    "#                          name=\"Set 1 -- 10 nA\"))\n",
    "# fig.add_trace(go.Scatter(mode='markers+lines', \n",
    "#                          x=escs2, y=int_ents2, \n",
    "#                          text=datnums2, \n",
    "#                          name=\"Set 2 -- 10 nA\"))\n",
    "# #                          marker=dict(color='LightSkyBlue',\n",
    "#                                      size=10,\n",
    "#                                      line=dict(color='DarkSlateGrey',\n",
    "#                                                width=2)),\n",
    "#                          error_y=dict(type='data', # value of error bar given in data coordinates\n",
    "#                                       array=[0.05]*len(int_ents),\n",
    "#                                       visible=True)))\n",
    "# fig.add_trace(go.Scatter(mode='lines', x=[-500,0], y=[np.log(2), np.log(2)], name=\"Log2\", line=dict(color='DarkSlateGrey', width=4, dash='dot')))  \n",
    "\n",
    "fig.update_layout(xaxis_title='ESC /mV', yaxis_title='Entropy /kb',\n",
    "                      title=f'Integrated -- Dats {dats[0].datnum} - {dats[-1].datnum}')\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(f'Exports/IntEntropyvalues_03_12_dats{datnums[0]}_{datnums[-1]}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-189.21"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dats[2].Logs.fds[\"ESC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
