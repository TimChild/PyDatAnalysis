{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add PyDatAnalysis to path\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, \"/Users/owensheekey/Documents/Research/PyDatAnalysis\")\n",
    "\n",
    "export_path = 'Exports/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from progressbar import progressbar\n",
    "from src.DatObject.Make_Dat import get_dat, get_dats\n",
    "import src.UsefulFunctions as U\n",
    "from src.DataStandardize.ExpSpecific.Feb21 import Feb21Exp2HDF, Feb21ExpConfig\n",
    "from src.DataStandardize.ExpConfig import ExpConfigGroupDatAttribute, ExpConfigBase\n",
    "import multiprocessing as mp\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "import lmfit as lm\n",
    "from typing import TYPE_CHECKING, Iterable, Optional\n",
    "from src.DatObject.Attributes.Transition import i_sense_digamma, i_sense, i_sense_digamma_quad\n",
    "from src.UsefulFunctions import edit_params\n",
    "from src.DatObject.Attributes.SquareEntropy import square_wave_time_array, integrate_entropy\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "import src.UsefulFunctions as U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dats = get_dats(range(1637, 1653), overwrite=True)\n",
    "#dats = get_dats(range(1653, 1669), overwrite=True)\n",
    "#dats = get_dats(range(1669, 1685), overwrite=True)\n",
    "\n",
    "#dats = get_dats(range(1778, 1795))\n",
    "dats = get_dats(range(1798, 1803))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def narrow_fit(dat, width, **kwargs):\n",
    "    '''\n",
    "    Get a fit only including +/- width in dat.x around center of transition\n",
    "    kwargs is the stuff to pass to get_fit\n",
    "    Return a fit\n",
    "    '''\n",
    "    x = np.copy(dat.SquareEntropy.avg_x)\n",
    "    y = np.copy(dat.SquareEntropy.default_Output.averaged)\n",
    "    y = np.mean(y[(0, 2), :], axis=0)\n",
    "\n",
    "    start_ind = np.nanargmin(np.abs(np.add(x, width)))\n",
    "    end_ind = np.nanargmin(np.abs(np.subtract(x, width)))\n",
    "\n",
    "    x[:start_ind] = [np.nan] * start_ind\n",
    "    x[end_ind:] = [np.nan] * (len(x) - end_ind)\n",
    "\n",
    "    y[:start_ind] = [np.nan] * start_ind\n",
    "    y[end_ind:] = [np.nan] * (len(y) - end_ind)\n",
    "\n",
    "    fit = dat.SquareEntropy.get_fit(\n",
    "        x=x,\n",
    "        data=y,\n",
    "        **kwargs)\n",
    "    return fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_calc(datnum, overwrite=True):\n",
    "    \"\"\"Just a function which can be passed to a process pool for faster calculation\"\"\"\n",
    "    save_name = 'SPS.005'\n",
    "\n",
    "    dat = get_dat(datnum)\n",
    "\n",
    "    setpoints = [0.005, None]\n",
    "\n",
    "    # Get other inputs\n",
    "    setpoint_times = square_wave_time_array(dat.SquareEntropy.square_awg)\n",
    "    sp_start, sp_fin = [U.get_data_index(setpoint_times, sp) for sp in setpoints]\n",
    "    logger.debug(f'Setpoint times: {setpoints}, Setpoint indexs: {sp_start, sp_fin}')\n",
    "\n",
    "    # Run Fits\n",
    "    pp = dat.SquareEntropy.get_ProcessParams(name=None,  # Load default and modify from there\n",
    "                                             setpoint_start=sp_start, setpoint_fin=sp_fin,\n",
    "                                             transition_fit_func=i_sense,\n",
    "                                             save_name=save_name)\n",
    "    out = dat.SquareEntropy.get_Outputs(name=save_name, inputs=None, process_params=pp, overwrite=overwrite)\n",
    "    dat.Entropy.get_fit(which='avg', name=save_name, data=out.average_entropy_signal, x=out.x, check_exists=False,\n",
    "                        overwrite=overwrite)\n",
    "    [dat.Entropy.get_fit(which='row', row=i, name=save_name,\n",
    "                         data=row, x=out.x, check_exists=False,\n",
    "                         overwrite=overwrite) for i, row in enumerate(out.entropy_signal)]\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "Θ = dats[0].SquareEntropy.avg_fit.best_values.theta \n",
    "fit = dats[0].SquareEntropy.get_fit(which='avg', which_fit='transition', transition_part='cold', check_exists=False)\n",
    "params = fit.params\n",
    "params.add('g', value=0, vary=True, min=-50, max=1000)\n",
    "new_pars = edit_params(params, param_name='theta', value=Θ, vary=False) # Based on some old DC bias scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.002760976692256251"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "narrow_fit(\n",
    "    dats[0],\n",
    "    400,\n",
    "    initial_params=new_pars,\n",
    "    fit_func=i_sense_digamma,\n",
    "    check_exists=False).best_values.mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5 of 5) |##########################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "amp_digamma_ = [narrow_fit(\n",
    "    dat,\n",
    "    400,\n",
    "    initial_params=new_pars, \n",
    "    fit_func=i_sense_digamma, \n",
    "    check_exists=False).best_values.amp\n",
    "for dat in progressbar(dats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5 of 5) |##########################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "g_digamma_ = [narrow_fit(\n",
    "    dat,\n",
    "    400,\n",
    "    initial_params=new_pars, \n",
    "    fit_func=i_sense_digamma, \n",
    "    check_exists=False).best_values.g\n",
    "for dat in progressbar(dats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5 of 5) |##########################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "theta_digamma_ = [narrow_fit(\n",
    "    dat,\n",
    "    400,\n",
    "    initial_params=new_pars, \n",
    "    fit_func=i_sense_digamma, \n",
    "    check_exists=False).best_values.theta\n",
    "for dat in progressbar(dats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5 of 5) |##########################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "mids_digamma_ = [narrow_fit(\n",
    "    dat,\n",
    "    400,\n",
    "    initial_params=new_pars, \n",
    "    fit_func=i_sense_digamma, \n",
    "    check_exists=False).best_values.mid\n",
    "for dat in progressbar(dats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5 of 5) |##########################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "amp_digamma_ = [narrow_fit(\n",
    "    dat,\n",
    "    400,\n",
    "    initial_params=new_pars, \n",
    "    fit_func=i_sense_digamma, \n",
    "    check_exists=False).best_values.amp\n",
    "for dat in progressbar(dats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.08056885e-05 -3.93451364e-02 -5.40995556e+00]\n"
     ]
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "datnums = [dat.datnum for dat in dats]\n",
    "escs = [dat.Logs.fds[\"ESC\"] for dat in dats]\n",
    "\n",
    "fig.add_trace(go.Scatter(mode='markers', x=escs, y=amp_digamma_, text=[dat.datnum for dat in dats], name=\"Data\"))\n",
    "fig.update_layout(xaxis_title='ESC/ mV', yaxis_title='Amplitude /nA',\n",
    "                      title=f'Dats {dats[0].datnum} - {dats[-1].datnum}')\n",
    "res = np.polyfit(escs, amp_digamma_, 2)\n",
    "fit = np.polyval(res, escs)\n",
    "print(res)\n",
    "fig.add_trace(go.Scatter(mode='lines', x=escs, y=fit, name=\"Fit\"))\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig.write_html(\"Exports/Set1_Ampl_03_07.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(mode='markers', x=escs, y=g_digamma_/Θ, text=[dat.datnum for dat in dats], name=\"Data\"))\n",
    "fig.update_layout(xaxis_title='ESC/ mV', yaxis_title='Gamma/Theta /arb',\n",
    "                      title=f'Dats {dats[0].datnum} - {dats[-1].datnum}')\n",
    "\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig.write_html(\"Exports/Set1_Gamma_03_07.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(mode='markers', x=escs, y=theta_digamma_, text=[dat.datnum for dat in dats], name=\"Data\"))\n",
    "fig.update_layout(xaxis_title='ESC/ mV', yaxis_title='Theta /mV',\n",
    "                      title=f'Dats {dats[0].datnum} - {dats[-1].datnum}')\n",
    "\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5 of 5) |##########################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "for dat in progressbar(dats):\n",
    "    x = dat.SquareEntropy.avg_x[::10]\n",
    "    y = dat.SquareEntropy.default_Output.averaged\n",
    "    y = np.mean(y[(0, 2), :], axis=0)[::10]\n",
    "    xfit = np.linspace(-500,500,1001)\n",
    "    fit = narrow_fit(\n",
    "            dat,\n",
    "            400,\n",
    "            initial_params=new_pars, \n",
    "            fit_func=i_sense_digamma, \n",
    "            check_exists=False)\n",
    "    yfit = fit.eval_fit(xfit)\n",
    "    fig.add_trace(go.Scatter(mode='markers', x=x, y=y, name=f'{dat.datnum}d'))\n",
    "    fig.add_trace(go.Scatter(mode='lines', x=xfit, y=yfit, name=f'{dat.datnum}f', marker_color='grey'))\n",
    "fig.update_layout(xaxis_title='ACC/100 /mV', yaxis_title='Current /nA',\n",
    "                      title=f'Dat {dats[0].datnum} - {dats[-1].datnum}')\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig.write_html(\"Exports/Set1_03_07_narrow_fitting.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deltaT(dat):\n",
    "    \"\"\"Returns deltaT of a given dat in mV\"\"\"\n",
    "    ho1 = dat.AWG.max(0)  # 'HO1/10M' gives nA * 10\n",
    "    t = dat.Logs.temps.mc\n",
    "\n",
    "    # Datnums to search through (only thing that should be changed)\n",
    "    datnums = set(range(1312, 1451+1)) - set(range(1312, 1451+1, 4))\n",
    "    # datnums = set()\n",
    "    # for j in range(5):\n",
    "    #     datnums = datnums.union(set(range(28 * j + 1312, 28 * j + 1312 + 4 * 7 + 1)) - set([28 * j + 1312 + 4 * i for i in range(8)]))\n",
    "    # datnums = list(datnums)\n",
    "\n",
    "    dats = get_dats(datnums)\n",
    "\n",
    "    dats = [d for d in dats if np.isclose(d.Logs.temps.mc, dat.Logs.temps.mc, rtol=0.1)]  # Get all dats where MC temp is within 10%\n",
    "    bias_lookup = np.array([d.Logs.fds['HO1/10M'] for d in dats])\n",
    "\n",
    "    indp = np.argmin(abs(bias_lookup - ho1))\n",
    "    indm = np.argmin(abs(bias_lookup + ho1))\n",
    "    theta_z = np.nanmean([d.Transition.avg_fit.best_values.theta for d in dats if d.Logs.fds['HO1/10M'] == 0])\n",
    "\n",
    "    # temp_lookup = np.array([d.Logs.temps.mc for d in dats])\n",
    "    # bias_lookup = np.array([d.Logs.fds['HO1/10M'] for d in dats])\n",
    "    #\n",
    "    # indp = np.argmin(temp_lookup - t + bias_lookup - ho1)\n",
    "    # indm = np.argmin(temp_lookup - t + bias_lookup + ho1)\n",
    "    # indz = np.argmin(temp_lookup - t + bias_lookup)\n",
    "\n",
    "    theta_p = dats[indp].Transition.avg_fit.best_values.theta\n",
    "    theta_m = dats[indm].Transition.avg_fit.best_values.theta\n",
    "    # theta_z = dats[indz].Transition.avg_fit.best_values.theta\n",
    "    return (theta_p + theta_m) / 2 - theta_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaT = [get_deltaT(dat) for dat in dats]\n",
    "ampl = amp_digamma_\n",
    "for i, dat in enumerate(dats):\n",
    "    dat.Entropy.set_integration_info(dT=deltaT[i], amp=ampl[i], overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "int_ents = []\n",
    "for i in range(len(dats)):\n",
    "    int_ent = integrate_entropy(dats[i].SquareEntropy.avg_entropy_signal, dats[i].Entropy.integration_info.sf)\n",
    "    int_ents.append(int_ent[-1])\n",
    "    fig.add_trace(go.Scatter(mode='markers', \n",
    "                             x=np.subtract(dats[i].SquareEntropy.avg_x, mids_digamma_[i]), \n",
    "                             y=int_ent,\n",
    "                             name= f'Gamma/Theta /arb = {np.divide(g_digamma_,Θ)[i]:.2f}'))\n",
    "\n",
    "fig.add_trace(go.Scatter(mode='lines', x=[-400,400], y=[np.log(2), np.log(2)], name=\"Log2\"))  \n",
    "fig.add_trace(go.Scatter(mode='lines', x=[-400,400], y=[np.log(3), np.log(3)], name=\"Log3\"))  \n",
    "fig.update_layout(xaxis_title='ACC/100 /mV', yaxis_title='Entropy /kb',\n",
    "                      title=f'Dats {dats[0].datnum} - {dats[-1].datnum}')\n",
    "fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig.write_html(\"Exports/Set1_03_07_narrow_fitting_allentropy.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1798:0.7397\n",
      "1799:0.7986\n",
      "1800:0.7860\n",
      "1801:0.8762\n",
      "1802:0.7346\n"
     ]
    }
   ],
   "source": [
    "for dn in datnums:\n",
    "    do_calc(dn)\n",
    "ents = [dat.Entropy.get_fit(which='avg', name=\"SPS.005\", check_exists=False).best_values.dS for dat in dats]\n",
    "for i in range(len(ents)):\n",
    "    print(f'{datnums[i]}:{ents[i]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(mode='markers+lines', x=escs, y=int_ents, text=[dat.datnum for dat in dats], name=\"Int\"))\n",
    "fig.add_trace(go.Scatter(mode='markers+lines', x=escs, y=ents, text=[dat.datnum for dat in dats], name=\"Fit\"))\n",
    "fig.update_layout(xaxis_title='ESC/ mV', yaxis_title='Fit Entropy /kb',\n",
    "                      title=f'Dats {dats[0].datnum} - {dats[-1].datnum}')\n",
    "\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fit found with same initial arguments, but hash does not match. Recalculating fit now\n"
     ]
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "int_ents = []\n",
    "\n",
    "for i, dat in enumerate(dats):\n",
    "    ent = dat.Entropy.get_fit(which='avg', name=\"SPS.005\", check_exists=True).best_values.dS\n",
    "    xfit = np.linspace(-500,500,1001)\n",
    "    entyfit = dat.Entropy.get_fit(which='avg', name=\"SPS.005\", check_exists=True).eval_fit(xfit)\n",
    "\n",
    "    fig.add_trace(go.Scatter(mode='markers', \n",
    "                             x=dat.SquareEntropy.avg_x, \n",
    "                             y=dat.SquareEntropy.avg_entropy_signal,\n",
    "                             name= f'Gamma/Theta /arb = {np.divide(g_digamma_,Θ)[i]:.2f}'))\n",
    "    fig.add_trace(go.Scatter(mode='lines', \n",
    "                             x=xfit, \n",
    "                             y=entyfit, \n",
    "                             name= f'delta S = {ent:.2f}',\n",
    "                             marker_color='grey'))\n",
    "\n",
    "fig.update_layout(xaxis_title='ACC/100 /mV', yaxis_title='Entropy /kb',\n",
    "                      title=f'Dats {dats[0].datnum} - {dats[-1].datnum}')\n",
    "fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
