{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add PyDatAnalysis to path\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, \"/Users/owensheekey/Documents/Research/PyDatAnalysis\")\n",
    "\n",
    "export_path = 'Exports/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from progressbar import progressbar\n",
    "from src.DatObject.Make_Dat import get_dat, get_dats\n",
    "import src.UsefulFunctions as U\n",
    "from src.DataStandardize.ExpSpecific.Feb21 import Feb21Exp2HDF, Feb21ExpConfig\n",
    "from src.DataStandardize.ExpConfig import ExpConfigGroupDatAttribute, ExpConfigBase\n",
    "import multiprocessing as mp\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "import lmfit as lm\n",
    "from typing import TYPE_CHECKING, Iterable, Optional\n",
    "from src.DatObject.Attributes.Transition import i_sense_digamma, i_sense, i_sense_digamma_quad\n",
    "from src.UsefulFunctions import edit_params\n",
    "from src.DatObject.Attributes.SquareEntropy import square_wave_time_array, integrate_entropy\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "import src.UsefulFunctions as U\n",
    "from src.CoreUtil import decimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def narrow_fit(dat, width, **kwargs):\n",
    "    '''\n",
    "    Get a fit only including +/- width in dat.x around center of transition\n",
    "    kwargs is the stuff to pass to get_fit\n",
    "    Return a fit\n",
    "    '''\n",
    "    out = dat.SquareEntropy.get_Outputs(existing_only=True)\n",
    "    x = np.copy(out.x)\n",
    "    y = np.copy(out.averaged)\n",
    "    y = np.mean(y[(0, 2), :], axis=0)\n",
    "\n",
    "    start_ind = np.nanargmin(np.abs(np.add(x, width)))\n",
    "    end_ind = np.nanargmin(np.abs(np.subtract(x, width)))\n",
    "\n",
    "    x[:start_ind] = [np.nan] * start_ind\n",
    "    x[end_ind:] = [np.nan] * (len(x) - end_ind)\n",
    "\n",
    "    y[:start_ind] = [np.nan] * start_ind\n",
    "    y[end_ind:] = [np.nan] * (len(y) - end_ind)\n",
    "\n",
    "    fit = dat.SquareEntropy.get_fit(\n",
    "        x=x,\n",
    "        data=y,\n",
    "        **kwargs)\n",
    "    return fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def narrow_fit_trans_only(dat, width, **kwargs):\n",
    "    '''\n",
    "    Get a fit only including +/- width in dat.x around center of transition\n",
    "    kwargs is the stuff to pass to get_fit\n",
    "    Return a fit\n",
    "    '''\n",
    "    x = np.copy(dat.Transition.avg_x)\n",
    "    y = np.copy(dat.Transition.avg_data)\n",
    "\n",
    "    start_ind = np.nanargmin(np.abs(np.add(x, width)))\n",
    "    end_ind = np.nanargmin(np.abs(np.subtract(x, width)))\n",
    "\n",
    "    x[:start_ind] = [np.nan] * start_ind\n",
    "    x[end_ind:] = [np.nan] * (len(x) - end_ind)\n",
    "\n",
    "    y[:start_ind] = [np.nan] * start_ind\n",
    "    y[end_ind:] = [np.nan] * (len(y) - end_ind)\n",
    "\n",
    "    fit = dat.Transition.get_fit(\n",
    "        x=x,\n",
    "        data=y,\n",
    "        **kwargs)\n",
    "    return fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def do_calc(datnum, overwrite=True):\n",
    "    \"\"\"Just a function which can be passed to a process pool for faster calculation\"\"\"\n",
    "    save_name = 'SPS.01'\n",
    "\n",
    "    dat = get_dat(datnum)\n",
    "\n",
    "    setpoints = [0.01, None]\n",
    "\n",
    "    # Get other inputs\n",
    "    setpoint_times = square_wave_time_array(dat.SquareEntropy.square_awg)\n",
    "    sp_start, sp_fin = [U.get_data_index(setpoint_times, sp) for sp in setpoints]\n",
    "    logger.debug(f'Setpoint times: {setpoints}, Setpoint indexs: {sp_start, sp_fin}')\n",
    "\n",
    "    # Run Fits\n",
    "    pp = dat.SquareEntropy.get_ProcessParams(name=None,  # Load default and modify from there\n",
    "                                             setpoint_start=sp_start, setpoint_fin=sp_fin,\n",
    "                                             transition_fit_func=i_sense,\n",
    "                                             save_name=save_name)\n",
    "    out = dat.SquareEntropy.get_Outputs(name=save_name, inputs=None, process_params=pp, overwrite=overwrite)\n",
    "    dat.Entropy.get_fit(which='avg', name=save_name, data=out.average_entropy_signal, x=out.x, check_exists=False,\n",
    "                        overwrite=overwrite)\n",
    "    [dat.Entropy.get_fit(which='row', row=i, name=save_name,\n",
    "                         data=row, x=out.x, check_exists=False,\n",
    "                         overwrite=overwrite) for i, row in enumerate(out.entropy_signal)]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_deltaT(dat):\n",
    "    \"\"\"Returns deltaT of a given dat in mV\"\"\"\n",
    "    ho1 = dat.AWG.max(0)  # 'HO1/10M' gives nA * 10\n",
    "    t = dat.Logs.temps.mc\n",
    "\n",
    "    # Datnums to search through (only thing that should be changed)\n",
    "    datnums = set(range(2143, 2156))\n",
    "    # datnums = set()\n",
    "    # for j in range(5):\n",
    "    #     datnums = datnums.union(set(range(28 * j + 1312, 28 * j + 1312 + 4 * 7 + 1)) - set([28 * j + 1312 + 4 * i for i in range(8)]))\n",
    "    # datnums = list(datnums)\n",
    "\n",
    "    dats = get_dats(datnums)\n",
    "\n",
    "    dats = [d for d in dats if np.isclose(d.Logs.temps.mc, dat.Logs.temps.mc, rtol=0.1)]  # Get all dats where MC temp is within 10%\n",
    "    bias_lookup = np.array([d.Logs.fds['HO1/10M'] for d in dats])\n",
    "\n",
    "    indp = np.argmin(abs(bias_lookup - ho1))\n",
    "    indm = np.argmin(abs(bias_lookup + ho1))\n",
    "    theta_z = np.nanmean([d.Transition.avg_fit.best_values.theta for d in dats if d.Logs.fds['HO1/10M'] == 0])\n",
    "\n",
    "    # temp_lookup = np.array([d.Logs.temps.mc for d in dats])\n",
    "    # bias_lookup = np.array([d.Logs.fds['HO1/10M'] for d in dats])\n",
    "    #\n",
    "    # indp = np.argmin(temp_lookup - t + bias_lookup - ho1)\n",
    "    # indm = np.argmin(temp_lookup - t + bias_lookup + ho1)\n",
    "    # indz = np.argmin(temp_lookup - t + bias_lookup)\n",
    "\n",
    "    theta_p = dats[indp].Transition.avg_fit.best_values.theta\n",
    "    theta_m = dats[indm].Transition.avg_fit.best_values.theta\n",
    "    # theta_z = dats[indz].Transition.avg_fit.best_values.theta\n",
    "    return (theta_p + theta_m) / 2 - theta_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_simple_avg(dat):\n",
    "    return dat.Data.get_data('Experiment Copy/x_array'), np.average(dat.Data.get_data('Experiment Copy/cscurrent_2d'), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datnums = set(range(1869, 1919)) - set(range(1870, 1919, 2))\n",
    "# transdatnums = set(range(1869, 1919)) - set(range(1869, 1919, 2))\n",
    "\n",
    "# datnums = np.sort(list(set(range(2089, 2095)) - set(range(2090, 2095, 2))))\n",
    "# transdatnums = np.sort(list(set(range(2089, 2095)) - set(range(2089, 2095, 2))))\n",
    "# datnums = np.sort(list(set(range(1778, 1795))))\n",
    "\n",
    "# datnums = np.sort(list(set(range(2156, 2162)) - set(range(2157, 2162, 2))))\n",
    "# transdatnums = np.sort(list(set(range(2156, 2162)) - set(range(2156, 2162, 2))))\n",
    "\n",
    "datnums = [2164,2167, 2170, 2176, 2160, 2131, 2178, 2180, 2182]\n",
    "transdatnums = [2165,2168, 2171, 2177, 2161, 2132, 2179, 2181, 2183]\n",
    "\n",
    "# datnums = np.sort(list(set(range(2095, 2143)) - set(range(2096, 2143, 2))))\n",
    "# transdatnums = np.sort(list(set(range(2095, 2143)) - set(range(2095, 2143, 2))))\n",
    "end = 2806\n",
    "datnums = np.sort(list(set(range(2659, end)) - set(range(2660, end, 2)) - set([2793])))\n",
    "transdatnums = np.sort(list(set(range(2659, end)) - set(range(2659, end, 2)) - set([2794])))\n",
    "# datnums = np.array([2699, 2719, 2731, 2737, 2741, 2757])\n",
    "# transdatnums = np.add(datnums, 1)\n",
    "#datnums = np.sort(list(set(range(3066, 3255+1))))\n",
    "datnums = np.sort(list(set(range(3451, 3551+1))))\n",
    "#datnums = np.sort(list(set(range(3085, 3244+1)) | set(range(3430, 3450+1))))\n",
    "#datnums = np.sort(list(set(range(3551, 3652+1))))\n",
    "datnums = np.sort(list(set(range(3671, 3698+1))))\n",
    "datnums = np.sort(list(set(range(3769, 3890+1))))\n",
    "transdatnums = np.sort(list((set(range(3898, 3902+1)) | set([3904,3907,3909, 3910, 3911, 3912, 3913, 3914, 3915, 3916, 3917, 3918])) - set([3899])))\n",
    "transdatnums = np.sort(list(set(range(3953, 3961+1))))\n",
    "transdatnums = np.sort(list(set(range(4220, 4228+1))))\n",
    "transdatnums = np.sort(list(set(range(4322, 4330+1))))\n",
    "transdatnums = np.sort(list(set(range(4333, 4340+1))))\n",
    "transdatnums = np.sort(list(set(range(5534, 5542+1)) - set([5539])))\n",
    "transdatnums = np.sort(list(set(range(5543, 5558+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5543, 5544, 5545, 5546, 5547, 5548, 5549, 5550, 5551, 5552, 5553,\n",
       "       5554, 5555, 5556, 5557, 5558])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transdatnums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dats = get_dats(list(datnums), overwrite=False)\n",
    "transdats = get_dats(list(transdatnums), overwrite=False) #np.mean(dat.Data.sweepgates_x[1][1:])\n",
    "escs = [dat.Logs.fds[\"ESC\"] for dat in transdats]\n",
    "iss = [dat.Logs.bds[\"IS\"] for dat in transdats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Θ = np.average([dat.SquareEntropy.get_fit(which='avg',which_fit='transition', transition_part='cold', check_exists=False).best_values.theta for dat in progressbar(dats)])\n",
    "fit = transdats[0].Transition.get_fit(which='avg', check_exists=False)\n",
    "Θ = 2.2\n",
    "params = fit.params\n",
    "params.add('g', value=0, vary=True, min=-50, max=1000)\n",
    "new_pars = edit_params(params, param_name='theta', value=Θ, vary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (8 of 8) |##########################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "'''USING SIMPLE FITS'''\n",
    "\n",
    "fits = []\n",
    "for dat in progressbar(transdats):\n",
    "    x, y = get_simple_avg(dat)\n",
    "    fits.append(dat.Transition.get_fit(data=y, x=x, check_exists=False, initial_params=new_pars, \n",
    "                fit_func=i_sense_digamma))\n",
    "amp_digamma_ = [f.best_values.amp for f in fits]\n",
    "g_digamma_ = [f.best_values.g for f in fits]\n",
    "theta_digamma_ = [f.best_values.theta for f in fits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (16 of 16) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "'''NOT USING SIMPLE FITS'''\n",
    "\n",
    "fits = []\n",
    "for dat in progressbar(transdats):\n",
    "    fits.append(dat.Transition.get_fit(which='avg', check_exists=False, initial_params=new_pars, \n",
    "                fit_func=i_sense_digamma))\n",
    "amp_digamma_ = [f.best_values.amp for f in fits]\n",
    "g_digamma_ = [f.best_values.g for f in fits]\n",
    "theta_digamma_ = [f.best_values.theta for f in fits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(mode='markers', x=iss, y=theta_digamma_, text=transdatnums, name=\"Transition fits\"))\n",
    "\n",
    "fig.update_layout(xaxis_title='IS /mV', yaxis_title='Theta /mV',\n",
    "                      title=f'Dats {transdats[0].datnum} - {transdats[-1].datnum}')\n",
    "fig.show(renderer=\"chrome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(f'Exports/Thetas_dats_{transdats[0].datnum}_{transdats[-1].datnum}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(mode='markers', x=escs, y=np.divide(g_digamma_,Θ), text=transdatnums, name=\"Transition fits\"))\n",
    "\n",
    "fig.update_layout(xaxis_title='ESC /mV', yaxis_title='g/t /arb',\n",
    "                      title=f'Dats {transdats[0].datnum} - {transdats[-1].datnum}')\n",
    "fig.show(renderer=\"chrome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(f'Exports/g_over_t_dats{transdats[0].datnum}_{transdats[-1].datnum}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |#                                                  | 7 Elapsed Time: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "for i, dat in progressbar(enumerate(transdats)):\n",
    "    x, y = get_simple_avg(dat)\n",
    "    xfit = np.linspace(-500,500,1001)\n",
    "    fit = fits[i]\n",
    "    yfit = np.subtract(fit.eval_fit(xfit), np.array(fit.best_values.lin*xfit))\n",
    "    fig.add_trace(go.Scatter(mode='markers', x=x[::10], y=y[::10] - fit.best_values.lin*x[::10], name=f'{transdatnums[i]}d'))\n",
    "    fig.add_trace(go.Scatter(mode='lines', x=xfit, y=yfit, name=f'{transdatnums[i]}f', marker_color='grey'))\n",
    "fig.update_layout(xaxis_title='IP1*200 /mV', yaxis_title='Current /nA',\n",
    "                      title=f'Dat {transdats[0].datnum} - {transdats[-1].datnum}')\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AUTO_BIN_SIZE',\n",
       " 'DEFAULT_DATA_NAME',\n",
       " '__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_avg_data',\n",
       " '_avg_data_std',\n",
       " '_avg_fit',\n",
       " '_avg_x',\n",
       " '_calculate_fit',\n",
       " '_check_default_group_attrs',\n",
       " '_create_group',\n",
       " '_generate_fit_path',\n",
       " '_generate_fit_saved_name',\n",
       " '_get_FitPaths',\n",
       " '_get_data',\n",
       " '_get_default_data',\n",
       " '_get_default_x',\n",
       " '_get_fit_from_path',\n",
       " '_get_fit_parent_group_name',\n",
       " '_get_fit_path_from_fit_id',\n",
       " '_get_fit_path_from_name',\n",
       " '_get_initialized_state',\n",
       " '_get_private_key',\n",
       " '_initialize',\n",
       " '_make_avg_data',\n",
       " '_row_fits',\n",
       " '_run_all_row_fits',\n",
       " '_save_fit',\n",
       " '_set_attr',\n",
       " '_set_data',\n",
       " '_set_default_data',\n",
       " '_set_default_fit_groups',\n",
       " '_set_default_x',\n",
       " '_write_default_group_attrs',\n",
       " 'avg_data',\n",
       " 'avg_data_std',\n",
       " 'avg_fit',\n",
       " 'avg_x',\n",
       " 'check_init',\n",
       " 'clear_caches',\n",
       " 'dat',\n",
       " 'data',\n",
       " 'default_data_names',\n",
       " 'description',\n",
       " 'fit_names',\n",
       " 'fit_paths',\n",
       " 'get_avg_data',\n",
       " 'get_centers',\n",
       " 'get_data',\n",
       " 'get_default_func',\n",
       " 'get_default_params',\n",
       " 'get_descriptor',\n",
       " 'get_fit',\n",
       " 'get_group_attr',\n",
       " 'get_row_fits',\n",
       " 'group_name',\n",
       " 'hdf',\n",
       " 'initialize_additional_FittingAttribute_minimum',\n",
       " 'initialize_maximum',\n",
       " 'initialize_minimum',\n",
       " 'initialized',\n",
       " 'property_del',\n",
       " 'property_prop',\n",
       " 'property_set',\n",
       " 'row_fits',\n",
       " 'set_data',\n",
       " 'set_data_descriptor',\n",
       " 'set_default_data_descriptors',\n",
       " 'set_group_attr',\n",
       " 'specific_data_descriptors_keys',\n",
       " 'version',\n",
       " 'x']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(transdats[0].Transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1356,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(f'Exports/Cold_hot_transitions_plus_fit_dats{dats[0].datnum}_{dats[-1].datnum}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-a47939960875>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mampl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.425\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdeltaT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.93\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEntropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_integration_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeltaT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mampl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dats' is not defined"
     ]
    }
   ],
   "source": [
    "ampl = [0.425 for dat in dats]\n",
    "deltaT = [0.93 for dat in dats]\n",
    "for i, dat in enumerate(dats):\n",
    "    dat.Entropy.set_integration_info(dT=deltaT[i], amp=ampl[i], overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.682913401502972\n"
     ]
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "int_ents = []\n",
    "int_ents_peaks = []\n",
    "for i in range(len(dats)):\n",
    "    width = dat.Entropy.get_fit(which='avg', name=\"SPS.01\", check_exists=True).best_values.theta*10\n",
    "    center = dat.Entropy.get_fit(which='avg', name=\"SPS.01\", check_exists=True).best_values.mid\n",
    "    indstart = np.argmin(np.abs(np.subtract(out[i].x, center-width)))\n",
    "    indend = np.argmin(np.abs(np.subtract(out[i].x, center+width)))\n",
    "    \n",
    "    int_ent = integrate_entropy(out[i].average_entropy_signal, dats[i].Entropy.integration_info.sf)\n",
    "    int_ents_peaks.append(max(int_ent))\n",
    "    int_ents.append(int_ent[-1])\n",
    "    fig.add_trace(go.Scatter(mode='markers', \n",
    "                             x=np.subtract(out[i].x, mids_digamma_[i]), \n",
    "                             y=int_ent,\n",
    "                             text=f'Int Ent = {int_ents[i]:.2f}',\n",
    "                             name= f'dat{dats[i].datnum}, IP*200:{dats[i].Logs.fds[\"IP1*200\"]}'))\n",
    "\n",
    "fig.update_layout(xaxis_title='ACC/100 /mV', yaxis_title='Entropy /kb',\n",
    "                      title=f'Dats {dats[0].datnum} - {dats[-1].datnum}')\n",
    "fig.show(renderer='browser')\n",
    "print(width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(f'Exports/IntEntropy_03_22_dats{dats[0].datnum}_{dats[-1].datnum}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "ents = [dat.Entropy.get_fit(which='avg', name=\"SPS.01\", check_exists=True).best_values.dS for dat in dats]\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(mode='markers', \n",
    "                         x=ips, y=int_ents, \n",
    "                         text=datnums, \n",
    "                         name=\"Int\",\n",
    "                         marker=dict(color='LightSkyBlue',\n",
    "                                     size=10,\n",
    "                                     line=dict(color='DarkSlateGrey',\n",
    "                                               width=2))))\n",
    "fig.add_trace(go.Scatter(mode='markers', \n",
    "                         x=ips, y=ents, \n",
    "                         text=datnums, \n",
    "                         name=\"Fit\",\n",
    "                         marker=dict(color='Brown',\n",
    "                                     size=10,\n",
    "                                     line=dict(color='DarkSlateGrey',\n",
    "                                               width=2))))\n",
    "fig.add_trace(go.Scatter(mode='markers', \n",
    "                         x=ips, y=int_ents_peaks, \n",
    "                         text=datnums, \n",
    "                         name=\"Integrated Peak\",\n",
    "                         marker=dict(color='Green',\n",
    "                                     size=10,\n",
    "                                     line=dict(color='DarkSlateGrey',\n",
    "                                               width=2))))\n",
    "\n",
    "\n",
    "fig.update_layout(xaxis_title='IP1/200 /mV', yaxis_title='Entropy /kb',\n",
    "                      title=f'Integrated -- Dats {dats[0].datnum} - {dats[-1].datnum}')\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(f'Exports/IntEntropyvalues_03_21_dats{datnums[0]}_{datnums[-1]}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(mode='markers', \n",
    "                         x=ips, y=np.subtract(int_ents_peaks,int_ents), \n",
    "                         text=datnums, \n",
    "                         name=\"Peak-Int\",\n",
    "                         marker=dict(color='Green',\n",
    "                                     size=10,\n",
    "                                     line=dict(color='DarkSlateGrey',\n",
    "                                               width=2))))\n",
    "\n",
    "fig.update_layout(xaxis_title='IP1/200 /mV', yaxis_title='Entropy /kb',\n",
    "                      title=f'Integrated -- Dats {dats[0].datnum} - {dats[-1].datnum}')\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i in range(len(dats)):\n",
    "    enty = out[i].average_entropy_signal\n",
    "    entx = out[i].x\n",
    "    fitent = dats[i].Entropy.get_fit(which='avg', name=\"SPS.01\", check_exists=True).eval_fit(entx)\n",
    "    ent = dats[i].Entropy.get_fit(which='avg', name=\"SPS.01\", check_exists=True).best_values.dS\n",
    "    fig.add_trace(go.Scatter(mode='markers', \n",
    "                             x=entx,\n",
    "                             y=enty,\n",
    "                             name= f'dat{dats[i].datnum}, IP*200:{dats[i].Logs.fds[\"IP1*200\"]}'))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(mode='lines', x=entx, y=fitent, name=f'{datnums[i]}f, {ent}', marker_color='grey'))\n",
    "\n",
    "fig.update_layout(xaxis_title='ACC/100 /mV', yaxis_title='Entropy /kb',\n",
    "                      title=f'Dats {dats[0].datnum} - {dats[-1].datnum}')\n",
    "fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(f'Exports/FitEntropy_03_22_dats{datnums[0]}_{datnums[-1]}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (34 of 34) |########################| Elapsed Time: 0:00:06 Time:  0:00:06\n"
     ]
    }
   ],
   "source": [
    "centers = [dat.SquareEntropy.get_fit(data=dat.Data.get_data('Experiment Copy/cscurrent_2d')[0],\n",
    "                                     name=\"Centers\",\n",
    "                                     x=dat.Data.get_data('Experiment Copy/x_array'),\n",
    "                                     which_fit='transition', \n",
    "                                     check_exists=False).best_values.mid\n",
    "for dat in progressbar(dats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_data = get_dat(3734)\n",
    "data = occ_data.Data.get_data('Experiment Copy/cscurrent_2d')\n",
    "x=occ_data.Data.get_data('Experiment Copy/x_array')\n",
    "y=occ_data.Data.get_data('Experiment Copy/y_array')\n",
    "accs = [dat.Logs.fds[\"ACC*100\"] for dat in dats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "ips_other = np.array(ips)\n",
    "fig.add_trace(go.Heatmap(\n",
    "                    z=np.diff(data), x=x[:-1], y=y))\n",
    "fig.add_trace(go.Scatter(mode='markers+lines', \n",
    "                         x=centers, y=ips_other, \n",
    "                         text=[dat.datnum for dat in dats],\n",
    "                         marker_color=\"White\"))\n",
    "fig.update_layout(xaxis_title='ACC*100 /mV', yaxis_title='IP1*200',\n",
    "                      title=f'Dats {dats[0].datnum} - {dats[-1].datnum}, dat{occ_data.datnum}')\n",
    "fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(f'Exports/Along_occ_03_21_{dats[0].datnum}_{dats[-1].datnum}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([-65, -60, -55, -50, -45, -40, -30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = arr+50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([195.28, 182.78, 170.28, 157.78, 145.28, 132.78, 107.78])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*-2.5 + 157.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = np.linspace(-520,-440,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = arr2 + 530"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-526.3, -533.8, -541.3, -548.8, -556.3, -563.8, -571.3, -578.8,\n",
       "       -586.3])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2*-0.75 + -518.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([200.28, 187.78, 175.28, 162.78, 150.28, 137.78, 112.78]) + 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([207.28, 194.78, 182.28, 169.78, 157.28, 144.78, 119.78])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
