{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Add PyDatAnalysis to path\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, \"/Users/owensheekey/Documents/Research/PyDatAnalysis\")\n",
    "\n",
    "export_path = 'Exports/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from progressbar import progressbar\n",
    "from src.DatObject.Make_Dat import get_dat, get_dats\n",
    "import src.UsefulFunctions as U\n",
    "from src.DataStandardize.ExpSpecific.Feb21 import Feb21Exp2HDF, Feb21ExpConfig\n",
    "from src.DataStandardize.ExpConfig import ExpConfigGroupDatAttribute, ExpConfigBase\n",
    "import multiprocessing as mp\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "import lmfit as lm\n",
    "from typing import TYPE_CHECKING, Iterable, Optional\n",
    "from src.DatObject.Attributes.Transition import i_sense_digamma, i_sense, i_sense_digamma_quad\n",
    "from src.UsefulFunctions import edit_params\n",
    "from src.DatObject.Attributes.SquareEntropy import square_wave_time_array, integrate_entropy\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "import src.UsefulFunctions as U\n",
    "from src.CoreUtil import decimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def narrow_fit(dat, width, **kwargs):\n",
    "    '''\n",
    "    Get a fit only including +/- width in dat.x around center of transition\n",
    "    kwargs is the stuff to pass to get_fit\n",
    "    Return a fit\n",
    "    '''\n",
    "    out = dat.SquareEntropy.get_Outputs(existing_only=True)\n",
    "    x = np.copy(out.x)\n",
    "    y = np.copy(out.averaged)\n",
    "    y = np.mean(y[(0, 2), :], axis=0)\n",
    "\n",
    "    start_ind = np.nanargmin(np.abs(np.add(x, width)))\n",
    "    end_ind = np.nanargmin(np.abs(np.subtract(x, width)))\n",
    "\n",
    "    x[:start_ind] = [np.nan] * start_ind\n",
    "    x[end_ind:] = [np.nan] * (len(x) - end_ind)\n",
    "\n",
    "    y[:start_ind] = [np.nan] * start_ind\n",
    "    y[end_ind:] = [np.nan] * (len(y) - end_ind)\n",
    "\n",
    "    fit = dat.SquareEntropy.get_fit(\n",
    "        x=x,\n",
    "        data=y,\n",
    "        **kwargs)\n",
    "    return fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def narrow_fit_trans_only(dat, width, **kwargs):\n",
    "    '''\n",
    "    Get a fit only including +/- width in dat.x around center of transition\n",
    "    kwargs is the stuff to pass to get_fit\n",
    "    Return a fit\n",
    "    '''\n",
    "    x = np.copy(dat.Transition.avg_x)\n",
    "    y = np.copy(dat.Transition.avg_data)\n",
    "\n",
    "    start_ind = np.nanargmin(np.abs(np.add(x, width)))\n",
    "    end_ind = np.nanargmin(np.abs(np.subtract(x, width)))\n",
    "\n",
    "    x[:start_ind] = [np.nan] * start_ind\n",
    "    x[end_ind:] = [np.nan] * (len(x) - end_ind)\n",
    "\n",
    "    y[:start_ind] = [np.nan] * start_ind\n",
    "    y[end_ind:] = [np.nan] * (len(y) - end_ind)\n",
    "\n",
    "    fit = dat.SquareEntropy.get_fit(\n",
    "        x=x,\n",
    "        data=y,\n",
    "        **kwargs)\n",
    "    return fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def do_calc(datnum, overwrite=True):\n",
    "    \"\"\"Just a function which can be passed to a process pool for faster calculation\"\"\"\n",
    "    save_name = 'SPS.01'\n",
    "\n",
    "    dat = get_dat(datnum)\n",
    "\n",
    "    setpoints = [0.01, None]\n",
    "\n",
    "    # Get other inputs\n",
    "    setpoint_times = square_wave_time_array(dat.SquareEntropy.square_awg)\n",
    "    sp_start, sp_fin = [U.get_data_index(setpoint_times, sp) for sp in setpoints]\n",
    "    logger.debug(f'Setpoint times: {setpoints}, Setpoint indexs: {sp_start, sp_fin}')\n",
    "\n",
    "    # Run Fits\n",
    "    pp = dat.SquareEntropy.get_ProcessParams(name=None,  # Load default and modify from there\n",
    "                                             setpoint_start=sp_start, setpoint_fin=sp_fin,\n",
    "                                             transition_fit_func=i_sense,\n",
    "                                             save_name=save_name)\n",
    "    out = dat.SquareEntropy.get_Outputs(name=save_name, inputs=None, process_params=pp, overwrite=overwrite)\n",
    "    dat.Entropy.get_fit(which='avg', name=save_name, data=out.average_entropy_signal, x=out.x, check_exists=False,\n",
    "                        overwrite=overwrite)\n",
    "    [dat.Entropy.get_fit(which='row', row=i, name=save_name,\n",
    "                         data=row, x=out.x, check_exists=False,\n",
    "                         overwrite=overwrite) for i, row in enumerate(out.entropy_signal)]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_deltaT(dat):\n",
    "    \"\"\"Returns deltaT of a given dat in mV\"\"\"\n",
    "    ho1 = dat.AWG.max(0)  # 'HO1/10M' gives nA * 10\n",
    "    t = dat.Logs.temps.mc\n",
    "\n",
    "    # Datnums to search through (only thing that should be changed)\n",
    "    datnums = set(range(2143, 2156))\n",
    "    # datnums = set()\n",
    "    # for j in range(5):\n",
    "    #     datnums = datnums.union(set(range(28 * j + 1312, 28 * j + 1312 + 4 * 7 + 1)) - set([28 * j + 1312 + 4 * i for i in range(8)]))\n",
    "    # datnums = list(datnums)\n",
    "\n",
    "    dats = get_dats(datnums)\n",
    "\n",
    "    dats = [d for d in dats if np.isclose(d.Logs.temps.mc, dat.Logs.temps.mc, rtol=0.1)]  # Get all dats where MC temp is within 10%\n",
    "    bias_lookup = np.array([d.Logs.fds['HO1/10M'] for d in dats])\n",
    "\n",
    "    indp = np.argmin(abs(bias_lookup - ho1))\n",
    "    indm = np.argmin(abs(bias_lookup + ho1))\n",
    "    theta_z = np.nanmean([d.Transition.avg_fit.best_values.theta for d in dats if d.Logs.fds['HO1/10M'] == 0])\n",
    "\n",
    "    # temp_lookup = np.array([d.Logs.temps.mc for d in dats])\n",
    "    # bias_lookup = np.array([d.Logs.fds['HO1/10M'] for d in dats])\n",
    "    #\n",
    "    # indp = np.argmin(temp_lookup - t + bias_lookup - ho1)\n",
    "    # indm = np.argmin(temp_lookup - t + bias_lookup + ho1)\n",
    "    # indz = np.argmin(temp_lookup - t + bias_lookup)\n",
    "\n",
    "    theta_p = dats[indp].Transition.avg_fit.best_values.theta\n",
    "    theta_m = dats[indm].Transition.avg_fit.best_values.theta\n",
    "    # theta_z = dats[indz].Transition.avg_fit.best_values.theta\n",
    "    return (theta_p + theta_m) / 2 - theta_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datnums = set(range(1869, 1919)) - set(range(1870, 1919, 2))\n",
    "# transdatnums = set(range(1869, 1919)) - set(range(1869, 1919, 2))\n",
    "\n",
    "# datnums = np.sort(list(set(range(2089, 2095)) - set(range(2090, 2095, 2))))\n",
    "# transdatnums = np.sort(list(set(range(2089, 2095)) - set(range(2089, 2095, 2))))\n",
    "# datnums = np.sort(list(set(range(1778, 1795))))\n",
    "\n",
    "# datnums = np.sort(list(set(range(2156, 2162)) - set(range(2157, 2162, 2))))\n",
    "# transdatnums = np.sort(list(set(range(2156, 2162)) - set(range(2156, 2162, 2))))\n",
    "\n",
    "datnums = [2164,2167, 2170, 2176, 2160, 2131, 2178, 2180, 2182]\n",
    "transdatnums = [2165,2168, 2171, 2177, 2161, 2132, 2179, 2181, 2183]\n",
    "\n",
    "# datnums = np.sort(list(set(range(2095, 2143)) - set(range(2096, 2143, 2))))\n",
    "# transdatnums = np.sort(list(set(range(2095, 2143)) - set(range(2095, 2143, 2))))\n",
    "end = 2806\n",
    "datnums = np.sort(list(set(range(2659, end)) - set(range(2660, end, 2)) - set([2793])))\n",
    "transdatnums = np.sort(list(set(range(2659, end)) - set(range(2659, end, 2)) - set([2794])))\n",
    "# datnums = np.array([2699, 2719, 2731, 2737, 2741, 2757])\n",
    "# transdatnums = np.add(datnums, 1)\n",
    "#datnums = np.sort(list(set(range(3066, 3255+1))))\n",
    "datnums = np.sort(list(set(range(3451, 3551+1))))\n",
    "#datnums = np.sort(list(set(range(3085, 3244+1)) | set(range(3430, 3450+1))))\n",
    "#datnums = np.sort(list(set(range(3551, 3652+1))))\n",
    "datnums = np.sort(list(set(range(3671, 3698+1))))\n",
    "datnums = np.sort(list(set(range(3769, 3890+1))))\n",
    "datnums = np.sort(list(set(range(3931, 3947+1))))\n",
    "datnums = np.sort(list(set(range(3985, 4015+1))))\n",
    "# datnums = np.sort(list(set(range(4017, 4047+1)) | set(range(4090, 4098+1))))\n",
    "# datnums = np.sort(list(set(range(4049, 4078+1)) | set(range(4099, 4106+1))))\n",
    "datnums = np.sort(list(set(range(4118, 4198+1))))\n",
    "datnums = np.sort(list(set(range(4238, 4318+1))))\n",
    "datnums = np.sort(list(set(range(4435, 4455+1))))\n",
    "datnums = np.sort(list(set(range(4468, 4494+1))))\n",
    "datnums = np.sort(list(set(range(4500, 4553+1))))\n",
    "# datnums = np.sort(list(set(range(4555, 4608+1))))\n",
    "# datnums = np.sort(list(set(range(4610, 4654+1))))\n",
    "datnums = np.sort(list(set(range(4668, 4721+1))))\n",
    "datnums = np.sort(list(set(range(4723, 4776+1))))\n",
    "datnums = np.sort(list(set(range(4783, 4820+1))))\n",
    "datnums = np.sort(list(set(range(4847, 4867+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "dats = get_dats(list(datnums), overwrite=False)\n",
    "# transdats = get_dats(list(transdatnums), overwrite=False) \\\\np.mean(dat.Data.sweepgates_x[1][1:])\n",
    "ips = [np.mean(dat.Data.sweepgates_x[1][1:]) for dat in dats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC*100': 69.887,\n",
       " 'CSQ': -84.228,\n",
       " 'ESC': -489.81,\n",
       " 'ESP': -557.56,\n",
       " 'HO1/10M': 0,\n",
       " 'HO2*1000': 0,\n",
       " 'IP1*2': 29.908,\n",
       " 'IP1*200': -768.43}"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dats[0].Logs.fds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47% (10 of 21) |###########             | Elapsed Time: 0:00:02 ETA:   0:00:02Need to make _init_mags more permanent...\n",
      " 52% (11 of 21) |############            | Elapsed Time: 0:00:04 ETA:   0:00:24Need to make _init_mags more permanent...\n",
      " 57% (12 of 21) |#############           | Elapsed Time: 0:00:07 ETA:   0:00:19Need to make _init_mags more permanent...\n",
      " 61% (13 of 21) |##############          | Elapsed Time: 0:00:09 ETA:   0:00:18Need to make _init_mags more permanent...\n",
      " 66% (14 of 21) |################        | Elapsed Time: 0:00:11 ETA:   0:00:17Need to make _init_mags more permanent...\n",
      " 71% (15 of 21) |#################       | Elapsed Time: 0:00:14 ETA:   0:00:14Need to make _init_mags more permanent...\n",
      " 76% (16 of 21) |##################      | Elapsed Time: 0:00:16 ETA:   0:00:11Need to make _init_mags more permanent...\n",
      " 80% (17 of 21) |###################     | Elapsed Time: 0:00:19 ETA:   0:00:10Need to make _init_mags more permanent...\n",
      " 85% (18 of 21) |####################    | Elapsed Time: 0:00:21 ETA:   0:00:07Need to make _init_mags more permanent...\n",
      " 90% (19 of 21) |#####################   | Elapsed Time: 0:00:24 ETA:   0:00:04Need to make _init_mags more permanent...\n",
      " 95% (20 of 21) |######################  | Elapsed Time: 0:00:26 ETA:   0:00:02Need to make _init_mags more permanent...\n",
      "100% (21 of 21) |########################| Elapsed Time: 0:00:29 Time:  0:00:29\n"
     ]
    }
   ],
   "source": [
    "out = [do_calc(dn, overwrite=False) for dn in progressbar(datnums)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Θ = np.average([dat.SquareEntropy.get_fit(which='avg',which_fit='transition', transition_part='cold', check_exists=False).best_values.theta for dat in progressbar(dats)])\n",
    "fit = dats[0].SquareEntropy.get_fit(which='avg',which_fit='transition', transition_part='cold', check_exists=False)\n",
    "Θ = 2.168\n",
    "params = fit.params\n",
    "params.add('g', value=Θ, vary=True, min=-50, max=1000)\n",
    "new_pars = edit_params(params, param_name='theta', value=Θ, vary=False)\n",
    "hot_pars = edit_params(params, param_name='theta', value=Θ, vary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transdats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7810dcbaf40c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfit_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi_sense_digamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     check_exists=False).best_values.amp\n\u001b[0;32m----> 8\u001b[0;31m for dat in progressbar(transdats)]\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'transdats' is not defined"
     ]
    }
   ],
   "source": [
    "amp_digamma_ = [narrow_fit_trans_only(\n",
    "    dat,\n",
    "    500,\n",
    "    which='avg', \n",
    "    initial_params=new_pars, \n",
    "    fit_func=i_sense_digamma, \n",
    "    check_exists=False).best_values.amp\n",
    "for dat in progressbar(transdats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1341,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (72 of 72) |########################| Elapsed Time: 0:00:01 Time:  0:00:01\n"
     ]
    }
   ],
   "source": [
    "g_digamma_ = [narrow_fit_trans_only(\n",
    "    dat,\n",
    "    500,\n",
    "    initial_params=new_pars, \n",
    "    fit_func=i_sense_digamma, \n",
    "    check_exists=False).best_values.g\n",
    "for dat in progressbar(transdats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (21 of 21) |########################| Elapsed Time: 0:00:01 Time:  0:00:01\n"
     ]
    }
   ],
   "source": [
    "amp_digamma_cold = [narrow_fit(\n",
    "    dat,\n",
    "    500,\n",
    "    initial_params=new_pars, \n",
    "    fit_func=i_sense_digamma, \n",
    "    check_exists=False).best_values.amp\n",
    "for dat in progressbar(dats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (21 of 21) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "mids_digamma_ = [narrow_fit(\n",
    "    dat,\n",
    "    500,\n",
    "    initial_params=new_pars, \n",
    "    fit_func=i_sense_digamma, \n",
    "    check_exists=False).best_values.mid\n",
    "for dat in progressbar(dats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (21 of 21) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "g_digamma_ = [narrow_fit(\n",
    "    dat,\n",
    "    500,\n",
    "    initial_params=new_pars, \n",
    "    fit_func=i_sense_digamma, \n",
    "    check_exists=False).best_values.g\n",
    "for dat in progressbar(dats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (54 of 54) |########################| Elapsed Time: 0:00:05 Time:  0:00:05\n"
     ]
    }
   ],
   "source": [
    "deltaT = [dat.SquareEntropy.get_fit(which='avg', \n",
    "                                       which_fit='transition', \n",
    "                                       transition_part='hot',\n",
    "                                       check_exists=False).best_values.theta\n",
    "            - dat.SquareEntropy.get_fit(which='avg', \n",
    "                                       which_fit='transition', \n",
    "                                       transition_part='cold',\n",
    "                                       check_exists=False).best_values.theta for dat in progressbar(dats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(mode='markers', x=ips, text=datnums, y=deltaT, name=\"Entropy fits\"))\n",
    "\n",
    "fig.update_layout(xaxis_title='IP1*200 /mV', yaxis_title='deltaT /mV',\n",
    "                      title=f'Dats {dats[0].datnum} - {dats[-1].datnum}')\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9546627984681944"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(deltaT[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(f'Exports/dT_03_17_dats{datnums[0]}_{datnums[-1]}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(mode='markers', x=ips, y=amp_digamma_cold, text=datnums, name=\"Transition fits\"))\n",
    "\n",
    "fig.update_layout(xaxis_title='IP1*200 /mV', yaxis_title='Amplitude /mV',\n",
    "                      title=f'Dats {dats[0].datnum} - {dats[-1].datnum}')\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36157357430913073"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(amp_digamma_cold[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(f'Exports/Ampl_03_17_dats{datnums[0]}_{datnums[-1]}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(mode='markers', x=ips, y=g_digamma_, text=datnums, name=\"Transition fits\"))\n",
    "\n",
    "fig.update_layout(xaxis_title='IP1*200 /mV', yaxis_title='Gamma /mV',\n",
    "                      title=f'Dats {dats[0].datnum} - {dats[-1].datnum}')\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |               #                                  | 53 Elapsed Time: 0:00:01\n"
     ]
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "for i, dat in progressbar(enumerate(dats)):\n",
    "    x = dat.SquareEntropy.avg_x\n",
    "    y = dat.SquareEntropy.default_Output.averaged\n",
    "    ycold = np.mean(y[(0, 2), :], axis=0)\n",
    "    yhot = np.mean(y[(1, 3), :], axis=0)\n",
    "    xfit = np.linspace(-100,100,1001)\n",
    "    fit = narrow_fit(\n",
    "            dat,\n",
    "            400,\n",
    "            initial_params=new_pars, \n",
    "            fit_func=i_sense_digamma, \n",
    "            check_exists=False)\n",
    "    yfit = fit.eval_fit(xfit) - fit.best_values.lin*xfit\n",
    "#     fig.add_trace(go.Scatter(mode='markers', x=x, y=ycold - fit.best_values.lin*x, name=f'{datnums[i]}d_cold'))\n",
    "#     fig.add_trace(go.Scatter(mode='markers', x=x, y=yhot - fit.best_values.lin*x, name=f'{datnums[i]}d_hot'))\n",
    "    fig.add_trace(go.Scatter(mode='markers', x=x, y=y[0, :] - fit.best_values.lin*x, name=f'{datnums[i]}d_v0_0'))\n",
    "    fig.add_trace(go.Scatter(mode='markers', x=x, y=y[1, :] - fit.best_values.lin*x, name=f'{datnums[i]}d_vp'))\n",
    "    fig.add_trace(go.Scatter(mode='markers', x=x, y=y[2, :] - fit.best_values.lin*x, name=f'{datnums[i]}d_v_0_1'))\n",
    "    fig.add_trace(go.Scatter(mode='markers', x=x, y=y[3, :] - fit.best_values.lin*x, name=f'{datnums[i]}d_vm'))\n",
    "    fig.add_trace(go.Scatter(mode='lines', x=xfit, y=yfit, name=f'{datnums[i]}f', marker_color='grey'))\n",
    "fig.update_layout(xaxis_title=dats[0].Logs.xlabel, yaxis_title='Current /nA',\n",
    "                      title=f'Dat {dats[0].datnum} - {dats[-1].datnum}')\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(f'Exports/Cold_hot_transitions_plus_fit_dats{dats[0].datnum}_{dats[-1].datnum}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "ampl = [0.44 for dat in dats]\n",
    "deltaT = [0.96 for dat in dats]\n",
    "for i, dat in enumerate(dats):\n",
    "    dat.Entropy.set_integration_info(dT=deltaT[i], amp=ampl[i], overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.55019579721074\n"
     ]
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "int_ents = []\n",
    "int_ents_peaks = []\n",
    "for i in range(len(dats)):\n",
    "    width = dat.Entropy.get_fit(which='avg', name=\"SPS.01\", check_exists=True).best_values.theta*10\n",
    "    center = dat.Entropy.get_fit(which='avg', name=\"SPS.01\", check_exists=True).best_values.mid\n",
    "    indstart = np.argmin(np.abs(np.subtract(out[i].x, center-width)))\n",
    "    indend = np.argmin(np.abs(np.subtract(out[i].x, center+width)))\n",
    "    \n",
    "    int_ent = integrate_entropy(out[i].average_entropy_signal, dats[i].Entropy.integration_info.sf)\n",
    "    int_ents_peaks.append(max(int_ent))\n",
    "    int_ents.append(int_ent[indend] - int_ent[indstart])\n",
    "    fig.add_trace(go.Scatter(mode='markers', \n",
    "                             x=np.subtract(out[i].x, mids_digamma_[i]), \n",
    "                             y=int_ent,\n",
    "                             text=f'Int Ent = {int_ents[i]:.2f}',\n",
    "                             name= f'dat{dats[i].datnum}, IP*200:{dats[i].Logs.fds[\"IP1*200\"]}'))\n",
    "\n",
    "fig.update_layout(xaxis_title=dats[0].Logs.xlabel, yaxis_title='Entropy /kb',\n",
    "                      title=f'Dats {dats[0].datnum} - {dats[-1].datnum}')\n",
    "fig.show(renderer='chrome')\n",
    "print(width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(f'Exports/IntEntropy_03_22_dats{dats[0].datnum}_{dats[-1].datnum}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "ents = [dat.Entropy.get_fit(which='avg', name=\"SPS.01\", check_exists=True).best_values.dS for dat in dats]\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(mode='markers', \n",
    "                         x=ips, y=int_ents, \n",
    "                         text=datnums, \n",
    "                         name=\"Int\",\n",
    "                         marker=dict(color='LightSkyBlue',\n",
    "                                     size=10,\n",
    "                                     line=dict(color='DarkSlateGrey',\n",
    "                                               width=2))))\n",
    "fig.add_trace(go.Scatter(mode='markers', \n",
    "                         x=ips, y=ents, \n",
    "                         text=datnums, \n",
    "                         name=\"Fit\",\n",
    "                         marker=dict(color='Brown',\n",
    "                                     size=10,\n",
    "                                     line=dict(color='DarkSlateGrey',\n",
    "                                               width=2))))\n",
    "fig.add_trace(go.Scatter(mode='markers', \n",
    "                         x=ips, y=int_ents_peaks, \n",
    "                         text=datnums, \n",
    "                         name=\"Integrated Peak\",\n",
    "                         marker=dict(color='Green',\n",
    "                                     size=10,\n",
    "                                     line=dict(color='DarkSlateGrey',\n",
    "                                               width=2))))\n",
    "\n",
    "\n",
    "fig.update_layout(xaxis_title=\"IP1*200 /mV\", yaxis_title='Entropy /kb',\n",
    "                      title=f'Integrated -- Dats {dats[0].datnum} - {dats[-1].datnum}')\n",
    "fig.show(renderer=\"chrome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(f'Exports/IntEntropyvalues_03_24_dats{datnums[0]}_{datnums[-1]}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(mode='markers', \n",
    "                         x=ips, y=np.subtract(int_ents_peaks,int_ents), \n",
    "                         text=datnums, \n",
    "                         name=\"Peak-Int\",\n",
    "                         marker=dict(color='Green',\n",
    "                                     size=10,\n",
    "                                     line=dict(color='DarkSlateGrey',\n",
    "                                               width=2))))\n",
    "\n",
    "fig.update_layout(xaxis_title='IP1*200 /mV', yaxis_title='Entropy /kb',\n",
    "                      title=f'Integrated -- Dats {dats[0].datnum} - {dats[-1].datnum}')\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i in range(len(dats)):\n",
    "    enty = out[i].average_entropy_signal\n",
    "    entx = out[i].x\n",
    "    fitent = dats[i].Entropy.get_fit(which='avg', name=\"SPS.01\", check_exists=True).eval_fit(entx)\n",
    "    ent = dats[i].Entropy.get_fit(which='avg', name=\"SPS.01\", check_exists=True).best_values.dS\n",
    "    fig.add_trace(go.Scatter(mode='markers', \n",
    "                             x=entx,\n",
    "                             y=enty,\n",
    "                             name= f'dat{dats[i].datnum}, IP*200:{dats[i].Logs.fds[\"IP1*200\"]}'))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(mode='lines', x=entx, y=fitent, name=f'{datnums[i]}f, {ent}', marker_color='grey'))\n",
    "\n",
    "fig.update_layout(xaxis_title=dats[0].Logs.xlabel, yaxis_title='Entropy /kb',\n",
    "                      title=f'Dats {dats[0].datnum} - {dats[-1].datnum}')\n",
    "fig.show(renderer='chrome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(f'Exports/FitEntropy_03_23_dats{datnums[0]}_{datnums[-1]}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (21 of 21) |########################| Elapsed Time: 0:00:02 Time:  0:00:02\n"
     ]
    }
   ],
   "source": [
    "centers = [dat.SquareEntropy.get_fit(data=dat.Data.get_data('Experiment Copy/cscurrent_2d')[0],\n",
    "                                     name=\"Centers\",\n",
    "                                     x=dat.Data.get_data('Experiment Copy/x_array'),\n",
    "                                     which_fit='transition', \n",
    "                                     check_exists=False).best_values.mid\n",
    "for dat in progressbar(dats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_data = get_dat(4846)\n",
    "data = occ_data.Data.get_data('Experiment Copy/cscurrent_2d')\n",
    "x=occ_data.Data.get_data('Experiment Copy/x_array')\n",
    "y=occ_data.Data.get_data('Experiment Copy/y_array')\n",
    "accs = [dat.Logs.fds[\"ACC*100\"] for dat in dats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "ips_other = np.array(ips)\n",
    "fig.add_trace(go.Heatmap(\n",
    "                    z=np.diff(data), x=x[:-1], y=y))\n",
    "fig.add_trace(go.Scatter(mode='markers', \n",
    "                         x=centers, y=ips_other, \n",
    "                         text=[dat.datnum for dat in dats],\n",
    "                         marker_color=\"White\"))\n",
    "fig.update_layout(xaxis_title='ACC*100 /mV', yaxis_title='IP1*200',\n",
    "                      title=f'Dats {dats[0].datnum} - {dats[-1].datnum}, dat{occ_data.datnum}')\n",
    "fig.show(renderer='chrome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(f'Exports/Along_occ_03_21_{dats[0].datnum}_{dats[-1].datnum}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
