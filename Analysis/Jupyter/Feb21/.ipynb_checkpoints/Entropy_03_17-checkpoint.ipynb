{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Add PyDatAnalysis to path\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, \"/Users/owensheekey/Documents/Research/PyDatAnalysis\")\n",
    "\n",
    "export_path = 'Exports/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from progressbar import progressbar\n",
    "from src.DatObject.Make_Dat import get_dat, get_dats\n",
    "import src.UsefulFunctions as U\n",
    "from src.DataStandardize.ExpSpecific.Feb21 import Feb21Exp2HDF, Feb21ExpConfig\n",
    "from src.DataStandardize.ExpConfig import ExpConfigGroupDatAttribute, ExpConfigBase\n",
    "import multiprocessing as mp\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "import lmfit as lm\n",
    "from typing import TYPE_CHECKING, Iterable, Optional\n",
    "from src.DatObject.Attributes.Transition import i_sense_digamma, i_sense, i_sense_digamma_quad\n",
    "from src.UsefulFunctions import edit_params\n",
    "from src.DatObject.Attributes.SquareEntropy import square_wave_time_array, integrate_entropy\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "import src.UsefulFunctions as U\n",
    "from src.CoreUtil import decimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def narrow_fit(dat, width, **kwargs):\n",
    "    '''\n",
    "    Get a fit only including +/- width in dat.x around center of transition\n",
    "    kwargs is the stuff to pass to get_fit\n",
    "    Return a fit\n",
    "    '''\n",
    "    out = dat.SquareEntropy.get_Outputs(existing_only=True)\n",
    "    x = np.copy(out.x)\n",
    "    y = np.copy(out.averaged)\n",
    "    y = np.mean(y[(0, 2), :], axis=0)\n",
    "\n",
    "    start_ind = np.nanargmin(np.abs(np.add(x, width)))\n",
    "    end_ind = np.nanargmin(np.abs(np.subtract(x, width)))\n",
    "\n",
    "    x[:start_ind] = [np.nan] * start_ind\n",
    "    x[end_ind:] = [np.nan] * (len(x) - end_ind)\n",
    "\n",
    "    y[:start_ind] = [np.nan] * start_ind\n",
    "    y[end_ind:] = [np.nan] * (len(y) - end_ind)\n",
    "\n",
    "    fit = dat.SquareEntropy.get_fit(\n",
    "        x=x,\n",
    "        data=y,\n",
    "        **kwargs)\n",
    "    return fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def narrow_fit_trans_only(dat, width, **kwargs):\n",
    "    '''\n",
    "    Get a fit only including +/- width in dat.x around center of transition\n",
    "    kwargs is the stuff to pass to get_fit\n",
    "    Return a fit\n",
    "    '''\n",
    "    x = np.copy(dat.Transition.avg_x)\n",
    "    y = np.copy(dat.Transition.avg_data)\n",
    "\n",
    "    start_ind = np.nanargmin(np.abs(np.add(x, width)))\n",
    "    end_ind = np.nanargmin(np.abs(np.subtract(x, width)))\n",
    "\n",
    "    x[:start_ind] = [np.nan] * start_ind\n",
    "    x[end_ind:] = [np.nan] * (len(x) - end_ind)\n",
    "\n",
    "    y[:start_ind] = [np.nan] * start_ind\n",
    "    y[end_ind:] = [np.nan] * (len(y) - end_ind)\n",
    "\n",
    "    fit = dat.SquareEntropy.get_fit(\n",
    "        x=x,\n",
    "        data=y,\n",
    "        **kwargs)\n",
    "    return fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def do_calc(datnum, overwrite=True):\n",
    "    \"\"\"Just a function which can be passed to a process pool for faster calculation\"\"\"\n",
    "    save_name = 'SPS.01'\n",
    "\n",
    "    dat = get_dat(datnum)\n",
    "\n",
    "    setpoints = [0.01, None]\n",
    "\n",
    "    # Get other inputs\n",
    "    setpoint_times = square_wave_time_array(dat.SquareEntropy.square_awg)\n",
    "    sp_start, sp_fin = [U.get_data_index(setpoint_times, sp) for sp in setpoints]\n",
    "    logger.debug(f'Setpoint times: {setpoints}, Setpoint indexs: {sp_start, sp_fin}')\n",
    "\n",
    "    # Run Fits\n",
    "    pp = dat.SquareEntropy.get_ProcessParams(name=None,  # Load default and modify from there\n",
    "                                             setpoint_start=sp_start, setpoint_fin=sp_fin,\n",
    "                                             transition_fit_func=i_sense,\n",
    "                                             save_name=save_name)\n",
    "    out = dat.SquareEntropy.get_Outputs(name=save_name, inputs=None, process_params=pp, overwrite=overwrite)\n",
    "    dat.Entropy.get_fit(which='avg', name=save_name, data=out.average_entropy_signal, x=out.x, check_exists=False,\n",
    "                        overwrite=overwrite)\n",
    "    [dat.Entropy.get_fit(which='row', row=i, name=save_name,\n",
    "                         data=row, x=out.x, check_exists=False,\n",
    "                         overwrite=overwrite) for i, row in enumerate(out.entropy_signal)]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_deltaT(dat):\n",
    "    \"\"\"Returns deltaT of a given dat in mV\"\"\"\n",
    "    ho1 = dat.AWG.max(0)  # 'HO1/10M' gives nA * 10\n",
    "    t = dat.Logs.temps.mc\n",
    "\n",
    "    # Datnums to search through (only thing that should be changed)\n",
    "    datnums = set(range(2143, 2156))\n",
    "    # datnums = set()\n",
    "    # for j in range(5):\n",
    "    #     datnums = datnums.union(set(range(28 * j + 1312, 28 * j + 1312 + 4 * 7 + 1)) - set([28 * j + 1312 + 4 * i for i in range(8)]))\n",
    "    # datnums = list(datnums)\n",
    "\n",
    "    dats = get_dats(datnums)\n",
    "\n",
    "    dats = [d for d in dats if np.isclose(d.Logs.temps.mc, dat.Logs.temps.mc, rtol=0.1)]  # Get all dats where MC temp is within 10%\n",
    "    bias_lookup = np.array([d.Logs.fds['HO1/10M'] for d in dats])\n",
    "\n",
    "    indp = np.argmin(abs(bias_lookup - ho1))\n",
    "    indm = np.argmin(abs(bias_lookup + ho1))\n",
    "    theta_z = np.nanmean([d.Transition.avg_fit.best_values.theta for d in dats if d.Logs.fds['HO1/10M'] == 0])\n",
    "\n",
    "    # temp_lookup = np.array([d.Logs.temps.mc for d in dats])\n",
    "    # bias_lookup = np.array([d.Logs.fds['HO1/10M'] for d in dats])\n",
    "    #\n",
    "    # indp = np.argmin(temp_lookup - t + bias_lookup - ho1)\n",
    "    # indm = np.argmin(temp_lookup - t + bias_lookup + ho1)\n",
    "    # indz = np.argmin(temp_lookup - t + bias_lookup)\n",
    "\n",
    "    theta_p = dats[indp].Transition.avg_fit.best_values.theta\n",
    "    theta_m = dats[indm].Transition.avg_fit.best_values.theta\n",
    "    # theta_z = dats[indz].Transition.avg_fit.best_values.theta\n",
    "    return (theta_p + theta_m) / 2 - theta_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1535,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datnums = set(range(1869, 1919)) - set(range(1870, 1919, 2))\n",
    "# transdatnums = set(range(1869, 1919)) - set(range(1869, 1919, 2))\n",
    "\n",
    "# datnums = np.sort(list(set(range(2089, 2095)) - set(range(2090, 2095, 2))))\n",
    "# transdatnums = np.sort(list(set(range(2089, 2095)) - set(range(2089, 2095, 2))))\n",
    "# datnums = np.sort(list(set(range(1778, 1795))))\n",
    "\n",
    "# datnums = np.sort(list(set(range(2156, 2162)) - set(range(2157, 2162, 2))))\n",
    "# transdatnums = np.sort(list(set(range(2156, 2162)) - set(range(2156, 2162, 2))))\n",
    "\n",
    "datnums = [2164,2167, 2170, 2176, 2160, 2131, 2178, 2180, 2182]\n",
    "transdatnums = [2165,2168, 2171, 2177, 2161, 2132, 2179, 2181, 2183]\n",
    "\n",
    "# datnums = np.sort(list(set(range(2095, 2143)) - set(range(2096, 2143, 2))))\n",
    "# transdatnums = np.sort(list(set(range(2095, 2143)) - set(range(2095, 2143, 2))))\n",
    "end = 2806\n",
    "datnums = np.sort(list(set(range(2659, end)) - set(range(2660, end, 2)) - set([2793])))\n",
    "transdatnums = np.sort(list(set(range(2659, end)) - set(range(2659, end, 2)) - set([2794])))\n",
    "# datnums = np.array([2699, 2719, 2731, 2737, 2741, 2757])\n",
    "# transdatnums = np.add(datnums, 1)\n",
    "datnums = list(range(3066, 3198+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1536,
   "metadata": {},
   "outputs": [],
   "source": [
    "dats = get_dats(list(datnums), overwrite=False)\n",
    "# transdats = get_dats(list(transdatnums), overwrite=False)\n",
    "ips = [np.mean(dat.Data.sweepgates_x[1][1:]) for dat in dats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1537,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-400.0,\n",
       " -463.44,\n",
       " -526.92004,\n",
       " -590.4,\n",
       " -653.87,\n",
       " -717.35,\n",
       " -780.82996,\n",
       " -844.30005,\n",
       " -907.78,\n",
       " -971.28,\n",
       " -1034.7,\n",
       " -1098.2,\n",
       " -1161.7,\n",
       " -1225.2,\n",
       " -1288.6,\n",
       " -1352.1,\n",
       " -1415.6,\n",
       " -1479.1,\n",
       " -500.0,\n",
       " -495.0,\n",
       " -490.0,\n",
       " -485.0,\n",
       " -480.0,\n",
       " -475.0,\n",
       " -470.0,\n",
       " -465.0,\n",
       " -460.0,\n",
       " -455.0,\n",
       " -450.0,\n",
       " -445.0,\n",
       " -440.0,\n",
       " -435.0,\n",
       " -430.0,\n",
       " -425.0,\n",
       " -420.0,\n",
       " -415.0,\n",
       " -410.0,\n",
       " -405.0,\n",
       " -400.0,\n",
       " -395.0,\n",
       " -390.0,\n",
       " -385.0,\n",
       " -380.0,\n",
       " -375.0,\n",
       " -370.0,\n",
       " -365.0,\n",
       " -360.0,\n",
       " -355.0,\n",
       " -350.0,\n",
       " -345.0,\n",
       " -340.0,\n",
       " -335.0,\n",
       " -330.0,\n",
       " -325.0,\n",
       " -320.0,\n",
       " -315.0,\n",
       " -310.0,\n",
       " -305.0,\n",
       " -300.0,\n",
       " -295.0,\n",
       " -290.0,\n",
       " -285.0,\n",
       " -280.0,\n",
       " -275.0,\n",
       " -270.0,\n",
       " -265.0,\n",
       " -260.0,\n",
       " -255.0,\n",
       " -250.0,\n",
       " -245.0,\n",
       " -240.0,\n",
       " -235.0,\n",
       " -230.0,\n",
       " -225.0,\n",
       " -220.0,\n",
       " -215.0,\n",
       " -210.0,\n",
       " -205.0,\n",
       " -200.0,\n",
       " -195.0,\n",
       " -190.0,\n",
       " -185.0,\n",
       " -180.0,\n",
       " -175.0,\n",
       " -170.0,\n",
       " -165.0,\n",
       " -160.0,\n",
       " -155.0,\n",
       " -150.0,\n",
       " -145.0,\n",
       " -140.0,\n",
       " -135.0,\n",
       " -130.0,\n",
       " -125.0,\n",
       " -120.0,\n",
       " -115.0,\n",
       " -110.0,\n",
       " -105.0,\n",
       " -100.0,\n",
       " -95.0,\n",
       " -90.0,\n",
       " -85.0,\n",
       " -80.0,\n",
       " -75.0,\n",
       " -70.0,\n",
       " -65.0,\n",
       " -60.000004,\n",
       " -55.0,\n",
       " -50.0,\n",
       " -45.0,\n",
       " -40.0,\n",
       " -35.0,\n",
       " -30.0,\n",
       " -25.0,\n",
       " -20.0,\n",
       " -15.0,\n",
       " -10.0,\n",
       " -5.0,\n",
       " 0.0,\n",
       " 5.0,\n",
       " 10.0,\n",
       " 15.0,\n",
       " 20.0,\n",
       " 25.0,\n",
       " 30.0,\n",
       " 35.0,\n",
       " 40.0,\n",
       " 45.0,\n",
       " 50.0,\n",
       " 55.0,\n",
       " 60.000004,\n",
       " 65.0,\n",
       " 70.0]"
      ]
     },
     "execution_count": 1537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1538,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34% (46 of 133) |#######                | Elapsed Time: 0:00:11 ETA:   0:00:23Need to make _init_mags more permanent...\n",
      " 35% (47 of 133) |########               | Elapsed Time: 0:00:14 ETA:   0:03:56Need to make _init_mags more permanent...\n",
      " 36% (48 of 133) |########               | Elapsed Time: 0:00:17 ETA:   0:03:33Need to make _init_mags more permanent...\n",
      " 36% (49 of 133) |########               | Elapsed Time: 0:00:19 ETA:   0:03:30Need to make _init_mags more permanent...\n",
      " 37% (50 of 133) |########               | Elapsed Time: 0:00:22 ETA:   0:03:25Need to make _init_mags more permanent...\n",
      " 38% (51 of 133) |########               | Elapsed Time: 0:00:24 ETA:   0:03:24Need to make _init_mags more permanent...\n",
      " 39% (52 of 133) |########               | Elapsed Time: 0:00:27 ETA:   0:03:43Need to make _init_mags more permanent...\n",
      " 39% (53 of 133) |#########              | Elapsed Time: 0:00:30 ETA:   0:03:26Need to make _init_mags more permanent...\n",
      " 40% (54 of 133) |#########              | Elapsed Time: 0:00:32 ETA:   0:03:11Need to make _init_mags more permanent...\n",
      " 41% (55 of 133) |#########              | Elapsed Time: 0:00:34 ETA:   0:03:10Need to make _init_mags more permanent...\n",
      " 42% (56 of 133) |#########              | Elapsed Time: 0:00:37 ETA:   0:03:10Need to make _init_mags more permanent...\n",
      " 42% (57 of 133) |#########              | Elapsed Time: 0:00:39 ETA:   0:03:07Need to make _init_mags more permanent...\n",
      " 43% (58 of 133) |##########             | Elapsed Time: 0:00:42 ETA:   0:02:59Need to make _init_mags more permanent...\n",
      " 44% (59 of 133) |##########             | Elapsed Time: 0:00:44 ETA:   0:02:53Need to make _init_mags more permanent...\n",
      " 45% (60 of 133) |##########             | Elapsed Time: 0:00:47 ETA:   0:03:01Need to make _init_mags more permanent...\n",
      " 45% (61 of 133) |##########             | Elapsed Time: 0:00:49 ETA:   0:02:51Need to make _init_mags more permanent...\n",
      " 46% (62 of 133) |##########             | Elapsed Time: 0:00:51 ETA:   0:02:53Need to make _init_mags more permanent...\n",
      " 47% (63 of 133) |##########             | Elapsed Time: 0:00:54 ETA:   0:02:53Need to make _init_mags more permanent...\n",
      " 48% (64 of 133) |###########            | Elapsed Time: 0:00:56 ETA:   0:02:56Need to make _init_mags more permanent...\n",
      " 48% (65 of 133) |###########            | Elapsed Time: 0:00:59 ETA:   0:02:50Need to make _init_mags more permanent...\n",
      " 49% (66 of 133) |###########            | Elapsed Time: 0:01:01 ETA:   0:02:44Need to make _init_mags more permanent...\n",
      " 50% (67 of 133) |###########            | Elapsed Time: 0:01:04 ETA:   0:02:46Need to make _init_mags more permanent...\n",
      " 51% (68 of 133) |###########            | Elapsed Time: 0:01:06 ETA:   0:02:35Need to make _init_mags more permanent...\n",
      " 51% (69 of 133) |###########            | Elapsed Time: 0:01:09 ETA:   0:02:32Need to make _init_mags more permanent...\n",
      " 52% (70 of 133) |############           | Elapsed Time: 0:01:11 ETA:   0:02:29Need to make _init_mags more permanent...\n",
      " 53% (71 of 133) |############           | Elapsed Time: 0:01:13 ETA:   0:02:27Need to make _init_mags more permanent...\n",
      " 54% (72 of 133) |############           | Elapsed Time: 0:01:16 ETA:   0:02:38Need to make _init_mags more permanent...\n",
      " 54% (73 of 133) |############           | Elapsed Time: 0:01:19 ETA:   0:02:33Need to make _init_mags more permanent...\n",
      " 55% (74 of 133) |############           | Elapsed Time: 0:01:21 ETA:   0:02:20Need to make _init_mags more permanent...\n",
      " 56% (75 of 133) |############           | Elapsed Time: 0:01:23 ETA:   0:02:20Need to make _init_mags more permanent...\n",
      " 57% (76 of 133) |#############          | Elapsed Time: 0:01:26 ETA:   0:02:17Need to make _init_mags more permanent...\n",
      " 57% (77 of 133) |#############          | Elapsed Time: 0:01:28 ETA:   0:02:10Need to make _init_mags more permanent...\n",
      " 58% (78 of 133) |#############          | Elapsed Time: 0:01:30 ETA:   0:02:09Need to make _init_mags more permanent...\n",
      " 59% (79 of 133) |#############          | Elapsed Time: 0:01:33 ETA:   0:02:08Need to make _init_mags more permanent...\n",
      " 60% (80 of 133) |#############          | Elapsed Time: 0:01:35 ETA:   0:02:09Need to make _init_mags more permanent...\n",
      " 60% (81 of 133) |##############         | Elapsed Time: 0:01:38 ETA:   0:02:01Need to make _init_mags more permanent...\n",
      " 61% (82 of 133) |##############         | Elapsed Time: 0:01:40 ETA:   0:02:01Need to make _init_mags more permanent...\n",
      " 62% (83 of 133) |##############         | Elapsed Time: 0:01:42 ETA:   0:01:58Need to make _init_mags more permanent...\n",
      " 63% (84 of 133) |##############         | Elapsed Time: 0:01:45 ETA:   0:01:56Need to make _init_mags more permanent...\n",
      " 63% (85 of 133) |##############         | Elapsed Time: 0:01:47 ETA:   0:01:55Need to make _init_mags more permanent...\n",
      " 64% (86 of 133) |##############         | Elapsed Time: 0:01:50 ETA:   0:02:00Need to make _init_mags more permanent...\n",
      " 65% (87 of 133) |###############        | Elapsed Time: 0:01:52 ETA:   0:01:50Need to make _init_mags more permanent...\n",
      " 66% (88 of 133) |###############        | Elapsed Time: 0:01:55 ETA:   0:01:48Need to make _init_mags more permanent...\n",
      " 66% (89 of 133) |###############        | Elapsed Time: 0:01:57 ETA:   0:01:43Need to make _init_mags more permanent...\n",
      " 67% (90 of 133) |###############        | Elapsed Time: 0:01:59 ETA:   0:01:39Need to make _init_mags more permanent...\n",
      " 68% (91 of 133) |###############        | Elapsed Time: 0:02:02 ETA:   0:01:38Need to make _init_mags more permanent...\n",
      " 69% (92 of 133) |###############        | Elapsed Time: 0:02:04 ETA:   0:01:35Need to make _init_mags more permanent...\n",
      " 69% (93 of 133) |################       | Elapsed Time: 0:02:06 ETA:   0:01:36Need to make _init_mags more permanent...\n",
      " 70% (94 of 133) |################       | Elapsed Time: 0:02:09 ETA:   0:01:30Need to make _init_mags more permanent...\n",
      " 71% (95 of 133) |################       | Elapsed Time: 0:02:11 ETA:   0:01:33Need to make _init_mags more permanent...\n",
      " 72% (96 of 133) |################       | Elapsed Time: 0:02:13 ETA:   0:01:26Need to make _init_mags more permanent...\n",
      " 72% (97 of 133) |################       | Elapsed Time: 0:02:16 ETA:   0:01:27Need to make _init_mags more permanent...\n",
      " 73% (98 of 133) |################       | Elapsed Time: 0:02:18 ETA:   0:01:22Need to make _init_mags more permanent...\n",
      " 74% (99 of 133) |#################      | Elapsed Time: 0:02:21 ETA:   0:01:19Need to make _init_mags more permanent...\n",
      " 75% (100 of 133) |################      | Elapsed Time: 0:02:23 ETA:   0:01:17Need to make _init_mags more permanent...\n",
      " 75% (101 of 133) |################      | Elapsed Time: 0:02:25 ETA:   0:01:17Need to make _init_mags more permanent...\n",
      " 76% (102 of 133) |################      | Elapsed Time: 0:02:28 ETA:   0:01:12Need to make _init_mags more permanent...\n",
      " 77% (103 of 133) |#################     | Elapsed Time: 0:02:30 ETA:   0:01:12Need to make _init_mags more permanent...\n",
      " 78% (104 of 133) |#################     | Elapsed Time: 0:02:33 ETA:   0:01:11Need to make _init_mags more permanent...\n",
      " 78% (105 of 133) |#################     | Elapsed Time: 0:02:35 ETA:   0:01:08Need to make _init_mags more permanent...\n",
      " 79% (106 of 133) |#################     | Elapsed Time: 0:02:37 ETA:   0:01:04Need to make _init_mags more permanent...\n",
      " 80% (107 of 133) |#################     | Elapsed Time: 0:02:40 ETA:   0:01:01Need to make _init_mags more permanent...\n",
      " 81% (108 of 133) |#################     | Elapsed Time: 0:02:42 ETA:   0:01:00Need to make _init_mags more permanent...\n",
      " 81% (109 of 133) |##################    | Elapsed Time: 0:02:44 ETA:   0:00:56Need to make _init_mags more permanent...\n",
      " 82% (110 of 133) |##################    | Elapsed Time: 0:02:47 ETA:   0:00:56Need to make _init_mags more permanent...\n",
      " 83% (111 of 133) |##################    | Elapsed Time: 0:02:49 ETA:   0:00:53Need to make _init_mags more permanent...\n",
      " 84% (112 of 133) |##################    | Elapsed Time: 0:02:52 ETA:   0:00:49Need to make _init_mags more permanent...\n",
      " 84% (113 of 133) |##################    | Elapsed Time: 0:02:54 ETA:   0:00:47Need to make _init_mags more permanent...\n",
      " 85% (114 of 133) |##################    | Elapsed Time: 0:02:56 ETA:   0:00:43Need to make _init_mags more permanent...\n",
      " 86% (115 of 133) |###################   | Elapsed Time: 0:02:59 ETA:   0:00:42Need to make _init_mags more permanent...\n",
      " 87% (116 of 133) |###################   | Elapsed Time: 0:03:01 ETA:   0:00:39Need to make _init_mags more permanent...\n",
      " 87% (117 of 133) |###################   | Elapsed Time: 0:03:03 ETA:   0:00:37Need to make _init_mags more permanent...\n",
      " 88% (118 of 133) |###################   | Elapsed Time: 0:03:06 ETA:   0:00:36Need to make _init_mags more permanent...\n",
      " 89% (119 of 133) |###################   | Elapsed Time: 0:03:08 ETA:   0:00:33Need to make _init_mags more permanent...\n",
      " 90% (120 of 133) |###################   | Elapsed Time: 0:03:11 ETA:   0:00:30Need to make _init_mags more permanent...\n",
      " 90% (121 of 133) |####################  | Elapsed Time: 0:03:13 ETA:   0:00:27Need to make _init_mags more permanent...\n",
      " 91% (122 of 133) |####################  | Elapsed Time: 0:03:15 ETA:   0:00:26Need to make _init_mags more permanent...\n",
      " 92% (123 of 133) |####################  | Elapsed Time: 0:03:18 ETA:   0:00:23Need to make _init_mags more permanent...\n",
      " 93% (124 of 133) |####################  | Elapsed Time: 0:03:46 ETA:   0:04:12Need to make _init_mags more permanent...\n",
      " 93% (125 of 133) |####################  | Elapsed Time: 0:03:49 ETA:   0:00:25Need to make _init_mags more permanent...\n",
      " 94% (126 of 133) |####################  | Elapsed Time: 0:03:51 ETA:   0:00:16Need to make _init_mags more permanent...\n",
      " 95% (127 of 133) |##################### | Elapsed Time: 0:03:54 ETA:   0:00:13Need to make _init_mags more permanent...\n",
      " 96% (128 of 133) |##################### | Elapsed Time: 0:03:56 ETA:   0:00:12Need to make _init_mags more permanent...\n",
      " 96% (129 of 133) |##################### | Elapsed Time: 0:03:58 ETA:   0:00:09Need to make _init_mags more permanent...\n",
      " 97% (130 of 133) |##################### | Elapsed Time: 0:04:01 ETA:   0:00:07Need to make _init_mags more permanent...\n",
      " 98% (131 of 133) |##################### | Elapsed Time: 0:04:03 ETA:   0:00:04Need to make _init_mags more permanent...\n",
      " 99% (132 of 133) |##################### | Elapsed Time: 0:04:05 ETA:   0:00:02Need to make _init_mags more permanent...\n",
      "100% (133 of 133) |######################| Elapsed Time: 0:04:08 Time:  0:04:08\n"
     ]
    }
   ],
   "source": [
    "out = [do_calc(dn, overwrite=False) for dn in progressbar(datnums)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1414,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (21 of 21) |########################| Elapsed Time: 0:00:01 Time:  0:00:01\n"
     ]
    }
   ],
   "source": [
    "Θ = np.average([dat.SquareEntropy.get_fit(which='avg',which_fit='transition', transition_part='cold', check_exists=False).best_values.theta for dat in progressbar(dats)])\n",
    "params = fit.params\n",
    "params.add('g', value=0, vary=False, min=-50, max=1000)\n",
    "new_pars = edit_params(params, param_name='theta', value=Θ, vary=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7835810831439622"
      ]
     },
     "execution_count": 1415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Θ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1340,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (72 of 72) |########################| Elapsed Time: 0:00:04 Time:  0:00:04\n"
     ]
    }
   ],
   "source": [
    "amp_digamma_ = [narrow_fit_trans_only(\n",
    "    dat,\n",
    "    500,\n",
    "    which='avg', \n",
    "    initial_params=new_pars, \n",
    "    fit_func=i_sense_digamma, \n",
    "    check_exists=False).best_values.amp\n",
    "for dat in progressbar(transdats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1341,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (72 of 72) |########################| Elapsed Time: 0:00:01 Time:  0:00:01\n"
     ]
    }
   ],
   "source": [
    "g_digamma_ = [narrow_fit_trans_only(\n",
    "    dat,\n",
    "    500,\n",
    "    initial_params=new_pars, \n",
    "    fit_func=i_sense_digamma, \n",
    "    check_exists=False).best_values.g\n",
    "for dat in progressbar(transdats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1539,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (133 of 133) |######################| Elapsed Time: 0:00:09 Time:  0:00:09\n"
     ]
    }
   ],
   "source": [
    "amp_digamma_cold = [narrow_fit(\n",
    "    dat,\n",
    "    500,\n",
    "    initial_params=new_pars, \n",
    "    fit_func=i_sense_digamma, \n",
    "    check_exists=False).best_values.amp\n",
    "for dat in progressbar(dats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1540,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (133 of 133) |######################| Elapsed Time: 0:00:03 Time:  0:00:03\n"
     ]
    }
   ],
   "source": [
    "mids_digamma_ = [narrow_fit(\n",
    "    dat,\n",
    "    500,\n",
    "    initial_params=new_pars, \n",
    "    fit_func=i_sense_digamma, \n",
    "    check_exists=False).best_values.mid\n",
    "for dat in progressbar(dats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1482,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "deltaT = [dat.SquareEntropy.get_fit(which='avg', \n",
    "                                       which_fit='transition', \n",
    "                                       transition_part='hot', \n",
    "                                       check_exists=False).best_values.theta\n",
    "            - dat.SquareEntropy.get_fit(which='avg', \n",
    "                                       which_fit='transition', \n",
    "                                       transition_part='cold', \n",
    "                                       check_exists=False).best_values.theta for dat in dats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1483,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(mode='markers', x=ips, text=datnums, y=deltaT, name=\"Entropy fits\"))\n",
    "\n",
    "fig.update_layout(xaxis_title='IP1*200 /mV', yaxis_title='deltaT /mV',\n",
    "                      title=f'Dats {dats[0].datnum} - {dats[-1].datnum}')\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1484,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9088066154646663"
      ]
     },
     "execution_count": 1484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(deltaT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig.write_html(f'Exports/dT_03_17_dats{datnums[0]}_{datnums[-1]}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1424,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(mode='markers', x=ips, y=amp_digamma_cold, text=datnums, name=\"Transition fits\"))\n",
    "\n",
    "fig.update_layout(xaxis_title='IP1*200 /mV', yaxis_title='Amplitude /mV',\n",
    "                      title=f'Dats {dats[0].datnum} - {dats[-1].datnum}')\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1459,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42922876622158107"
      ]
     },
     "execution_count": 1459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(amp_digamma_cold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig.write_html(f'Exports/Ampl_03_17_dats{datnums[0]}_{datnums[-1]}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1553,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |          #                                      | 132 Elapsed Time: 0:00:08\n"
     ]
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "for i, dat in progressbar(enumerate(dats)):\n",
    "    x = dat.SquareEntropy.avg_x\n",
    "    y = dat.SquareEntropy.default_Output.averaged\n",
    "    ycold = np.mean(y[(0, 2), :], axis=0)\n",
    "    yhot = np.mean(y[(1, 3), :], axis=0)\n",
    "    xfit = np.linspace(-100,100,1001)\n",
    "    fit = narrow_fit(\n",
    "            dat,\n",
    "            400,\n",
    "            initial_params=new_pars, \n",
    "            fit_func=i_sense_digamma, \n",
    "            check_exists=False)\n",
    "    yfit = fit.eval_fit(xfit) - fit.best_values.lin*xfit\n",
    "    fig.add_trace(go.Scatter(mode='markers', x=x, y=ycold - fit.best_values.lin*x, name=f'{datnums[i]}d_cold'))\n",
    "    fig.add_trace(go.Scatter(mode='markers', x=x, y=yhot - fit.best_values.lin*x, name=f'{datnums[i]}d_hot'))\n",
    "    fig.add_trace(go.Scatter(mode='lines', x=xfit, y=yfit, name=f'{datnums[i]}f', marker_color='grey'))\n",
    "fig.update_layout(xaxis_title='ACC/100 /mV', yaxis_title='Current /nA',\n",
    "                      title=f'Dat {dats[0].datnum} - {dats[-1].datnum}')\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1356,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(f'Exports/Cold_hot_transitions_plus_fit_dats{dats[0].datnum}_{dats[-1].datnum}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1541,
   "metadata": {},
   "outputs": [],
   "source": [
    "ampl = [0.429 for dat in dats]\n",
    "deltaT = [0.908 for dat in dats]\n",
    "for i, dat in enumerate(dats):\n",
    "    dat.Entropy.set_integration_info(dT=deltaT[i], amp=ampl[i], overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1552,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "int_ents = []\n",
    "for i in range(len(dats)):\n",
    "#     width = dat.Entropy.get_fit(which='avg', name=\"SPS.01\", check_exists=True).best_values.theta*10\n",
    "#     center = dat.Entropy.get_fit(which='avg', name=\"SPS.01\", check_exists=True).best_values.mid\n",
    "#     indstart = np.argmin(np.abs(np.subtract(out[i].x, center-width)))\n",
    "#     indend = np.argmin(np.abs(np.subtract(out[i].x, center+width)))\n",
    "    \n",
    "    int_ent = integrate_entropy(out[i].average_entropy_signal[indstart:indend], dats[i].Entropy.integration_info.sf)\n",
    "    int_ents.append(np.average(int_ent[-10:]))\n",
    "    fig.add_trace(go.Scatter(mode='markers', \n",
    "                             x=np.subtract(out[i].x, mids_digamma_[i])[indstart:indend], \n",
    "                             y=int_ent,\n",
    "                             name= f'dat{dats[i].datnum}, IP*200:{dats[i].Logs.fds[\"IP1*200\"]}'))\n",
    "\n",
    "fig.update_layout(xaxis_title='ACC/100 /mV', yaxis_title='Entropy /kb',\n",
    "                      title=f'Dats {dats[0].datnum} - {dats[-1].datnum}')\n",
    "fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1214,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(f'Exports/IntEntropy_03_17_dats{dats[0].datnum}_{dats[-1].datnum}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1550,
   "metadata": {},
   "outputs": [],
   "source": [
    "ents = [dat.Entropy.get_fit(which='avg', name=\"SPS.01\", check_exists=True).best_values.dS for dat in dats]\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(mode='markers', \n",
    "                         x=ips, y=int_ents, \n",
    "                         text=datnums, \n",
    "                         name=\"Int\",\n",
    "                         marker=dict(color='LightSkyBlue',\n",
    "                                     size=10,\n",
    "                                     line=dict(color='DarkSlateGrey',\n",
    "                                               width=2))))\n",
    "fig.add_trace(go.Scatter(mode='markers', \n",
    "                         x=ips, y=ents, \n",
    "                         text=datnums, \n",
    "                         name=\"Fit\",\n",
    "                         marker=dict(color='Brown',\n",
    "                                     size=10,\n",
    "                                     line=dict(color='DarkSlateGrey',\n",
    "                                               width=2))))\n",
    "\n",
    "fig.update_layout(xaxis_title='IP1/200 /mV', yaxis_title='Entropy /kb',\n",
    "                      title=f'Integrated -- Dats {dats[0].datnum} - {dats[-1].datnum}')\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1378,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(f'Exports/IntEntropyvalues_03_17_dats{datnums[0]}_{datnums[-1]}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1543,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i in range(len(dats)):\n",
    "    enty = out[i].average_entropy_signal\n",
    "    entx = out[i].x\n",
    "    fitent = dats[i].Entropy.get_fit(which='avg', name=\"SPS.01\", check_exists=True).eval_fit(entx)\n",
    "    ent = dats[i].Entropy.get_fit(which='avg', name=\"SPS.01\", check_exists=True).best_values.dS\n",
    "    fig.add_trace(go.Scatter(mode='markers', \n",
    "                             x=entx,\n",
    "                             y=enty,\n",
    "                             name= f'dat{dats[i].datnum}, IP*200:{dats[i].Logs.fds[\"IP1*200\"]}'))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(mode='lines', x=entx, y=fitent, name=f'{datnums[i]}f, {ent}', marker_color='grey'))\n",
    "\n",
    "fig.update_layout(xaxis_title='ACC/100 /mV', yaxis_title='Entropy /kb',\n",
    "                      title=f'Dats {dats[0].datnum} - {dats[-1].datnum}')\n",
    "fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1450,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_data = get_dat(3064)\n",
    "data = occ_data.Data.get_data('Experiment Copy/cscurrent_2d')\n",
    "x=occ_data.Data.get_data('Experiment Copy/x_array')\n",
    "y=occ_data.Data.get_data('Experiment Copy/y_array')\n",
    "accs = [dat.Logs.fds[\"ACC*100\"] for dat in dats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1452,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Heatmap(\n",
    "                    z=np.diff(data), x=x[:-1], y=y))\n",
    "fig.add_trace(go.Scatter(mode='markers+lines', \n",
    "                         x=ips, y=accs, \n",
    "                         text=[dat.datnum for dat in dats],\n",
    "                         marker_color=\"White\"))\n",
    "fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const=0\n",
       "dS=0.25797\n",
       "dT=0.051717\n",
       "mid=-0.61138\n",
       "theta=4.4479"
      ]
     },
     "execution_count": 1545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dats[-1].Entropy.get_fit(which='avg', name=\"SPS.01\", check_exists=True).best_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
